#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æå–æ¨¡å— - ä»Twitteré¡µé¢ä¸­æå–æ¨æ–‡å†…å®¹ã€ç”¨æˆ·ä¿¡æ¯å’Œç›¸å…³æ•°æ®
æ”¯æŒå¤šç§æ•°æ®æ ¼å¼æå–ã€å†…å®¹æ¸…ç†å’Œæ•°æ®éªŒè¯
"""

import re
import json
import logging
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from urllib.parse import urlparse, parse_qs
import html
from bs4 import BeautifulSoup

from exception_handler import (
    ParsingException, ValidationException, 
    handle_exception, retry_on_error
)
from browser_manager import BrowserInstance


@dataclass
class TweetData:
    """æ¨æ–‡æ•°æ®æ¨¡å‹"""
    # åŸºæœ¬ä¿¡æ¯
    tweet_id: str
    user_id: str
    username: str
    display_name: str
    content: str
    
    # æ—¶é—´ä¿¡æ¯
    created_at: datetime
    scraped_at: datetime = field(default_factory=datetime.now)
    
    # äº’åŠ¨æ•°æ®
    likes_count: int = 0
    retweets_count: int = 0
    replies_count: int = 0
    quotes_count: int = 0
    views_count: int = 0
    
    # åª’ä½“ä¿¡æ¯
    media_urls: List[str] = field(default_factory=list)
    media_types: List[str] = field(default_factory=list)
    
    # é“¾æ¥ä¿¡æ¯
    urls: List[str] = field(default_factory=list)
    hashtags: List[str] = field(default_factory=list)
    mentions: List[str] = field(default_factory=list)
    
    # æ¨æ–‡ç±»å‹
    is_retweet: bool = False
    is_reply: bool = False
    is_quote: bool = False
    is_thread: bool = False
    
    # åŸå§‹æ¨æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯è½¬æ¨ï¼‰
    original_tweet_id: Optional[str] = None
    original_user_id: Optional[str] = None
    original_username: Optional[str] = None
    
    # å›å¤ä¿¡æ¯
    reply_to_tweet_id: Optional[str] = None
    reply_to_user_id: Optional[str] = None
    reply_to_username: Optional[str] = None
    
    # ä½ç½®ä¿¡æ¯
    location: Optional[str] = None
    
    # è¯­è¨€
    language: Optional[str] = None
    
    # åŸå§‹æ•°æ®
    raw_html: Optional[str] = None
    raw_json: Optional[Dict[str, Any]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        # å¤„ç†datetimeå¯¹è±¡
        for key, value in data.items():
            if isinstance(value, datetime):
                data[key] = value.isoformat()
        return data
    
    @property
    def engagement_rate(self) -> float:
        """äº’åŠ¨ç‡"""
        total_engagement = self.likes_count + self.retweets_count + self.replies_count
        if self.views_count > 0:
            return (total_engagement / self.views_count) * 100
        return 0.0
    
    @property
    def content_length(self) -> int:
        """å†…å®¹é•¿åº¦"""
        return len(self.content)
    
    @property
    def has_media(self) -> bool:
        """æ˜¯å¦åŒ…å«åª’ä½“"""
        return len(self.media_urls) > 0
    
    @property
    def has_links(self) -> bool:
        """æ˜¯å¦åŒ…å«é“¾æ¥"""
        return len(self.urls) > 0


@dataclass
class UserData:
    """ç”¨æˆ·æ•°æ®æ¨¡å‹"""
    user_id: str
    username: str
    display_name: str
    bio: str = ""
    location: str = ""
    website: str = ""
    
    # ç»Ÿè®¡ä¿¡æ¯
    followers_count: int = 0
    following_count: int = 0
    tweets_count: int = 0
    likes_count: int = 0
    
    # è´¦å·ä¿¡æ¯
    verified: bool = False
    protected: bool = False
    created_at: Optional[datetime] = None
    
    # å¤´åƒå’ŒèƒŒæ™¯
    profile_image_url: str = ""
    banner_image_url: str = ""
    
    # æŠ“å–ä¿¡æ¯
    scraped_at: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        # å¤„ç†datetimeå¯¹è±¡
        for key, value in data.items():
            if isinstance(value, datetime):
                data[key] = value.isoformat()
        return data


class DataExtractor:
    """æ•°æ®æå–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.url_pattern = re.compile(r'https?://[^\s]+')
        self.hashtag_pattern = re.compile(r'#\w+')
        self.mention_pattern = re.compile(r'@\w+')
        self.tweet_id_pattern = re.compile(r'/status/(\d+)')
        self.user_id_pattern = re.compile(r'/user/(\d+)')
        
        # æ—¶é—´æ ¼å¼
        self.time_formats = [
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%SZ',
            '%a %b %d %H:%M:%S %z %Y',
        ]
    
    async def extract_tweets_from_page(self, browser_instance: BrowserInstance, 
                                     max_tweets: int = 50) -> List[TweetData]:
        """ä»é¡µé¢æå–æ¨æ–‡æ•°æ®"""
        try:
            tweets = []
            
            # ç­‰å¾…æ¨æ–‡åŠ è½½
            await browser_instance.page.wait_for_selector('[data-testid="tweet"]', timeout=10000)
            
            # è·å–æ‰€æœ‰æ¨æ–‡å…ƒç´ 
            tweet_elements = await browser_instance.page.query_selector_all('[data-testid="tweet"]')
            
            self.logger.info(f"æ‰¾åˆ° {len(tweet_elements)} ä¸ªæ¨æ–‡å…ƒç´ ")
            
            for i, element in enumerate(tweet_elements[:max_tweets]):
                try:
                    tweet_data = await self._extract_single_tweet(browser_instance, element)
                    if tweet_data:
                        tweets.append(tweet_data)
                        self.logger.debug(f"æå–æ¨æ–‡ {i+1}: {tweet_data.tweet_id}")
                except Exception as e:
                    self.logger.warning(f"æå–ç¬¬ {i+1} ä¸ªæ¨æ–‡å¤±è´¥: {e}")
                    continue
            
            self.logger.info(f"æˆåŠŸæå– {len(tweets)} æ¡æ¨æ–‡")
            return tweets
            
        except Exception as e:
            self.logger.error(f"ä»é¡µé¢æå–æ¨æ–‡å¤±è´¥: {e}")
            handle_exception(e, {"max_tweets": max_tweets})
            return []
    
    async def _extract_single_tweet(self, browser_instance: BrowserInstance, 
                                   tweet_element) -> Optional[TweetData]:
        """æå–å•æ¡æ¨æ–‡æ•°æ®"""
        try:
            # è·å–æ¨æ–‡HTML
            tweet_html = await tweet_element.inner_html()
            
            # ä½¿ç”¨BeautifulSoupè§£æ
            soup = BeautifulSoup(tweet_html, 'html.parser')
            
            # æå–åŸºæœ¬ä¿¡æ¯
            tweet_id = await self._extract_tweet_id(tweet_element)
            if not tweet_id:
                return None
            
            # æå–ç”¨æˆ·ä¿¡æ¯
            user_info = await self._extract_user_info(tweet_element)
            if not user_info:
                return None
            
            # æå–æ¨æ–‡å†…å®¹
            content = await self._extract_tweet_content(tweet_element)
            
            # æå–æ—¶é—´
            created_at = await self._extract_tweet_time(tweet_element)
            
            # æå–äº’åŠ¨æ•°æ®
            engagement = await self._extract_engagement_data(tweet_element)
            
            # æå–åª’ä½“ä¿¡æ¯
            media_info = await self._extract_media_info(tweet_element)
            
            # æå–é“¾æ¥ã€æ ‡ç­¾ã€æåŠ
            links_info = await self._extract_links_info(content)
            
            # æ£€æµ‹æ¨æ–‡ç±»å‹
            tweet_type = await self._detect_tweet_type(tweet_element, content)
            
            # åˆ›å»ºæ¨æ–‡æ•°æ®å¯¹è±¡
            tweet_data = TweetData(
                tweet_id=tweet_id,
                user_id=user_info.get('user_id', ''),
                username=user_info.get('username', ''),
                display_name=user_info.get('display_name', ''),
                content=content,
                created_at=created_at,
                
                # äº’åŠ¨æ•°æ®
                likes_count=engagement.get('likes', 0),
                retweets_count=engagement.get('retweets', 0),
                replies_count=engagement.get('replies', 0),
                quotes_count=engagement.get('quotes', 0),
                views_count=engagement.get('views', 0),
                
                # åª’ä½“ä¿¡æ¯
                media_urls=media_info.get('urls', []),
                media_types=media_info.get('types', []),
                
                # é“¾æ¥ä¿¡æ¯
                urls=links_info.get('urls', []),
                hashtags=links_info.get('hashtags', []),
                mentions=links_info.get('mentions', []),
                
                # æ¨æ–‡ç±»å‹
                is_retweet=tweet_type.get('is_retweet', False),
                is_reply=tweet_type.get('is_reply', False),
                is_quote=tweet_type.get('is_quote', False),
                is_thread=tweet_type.get('is_thread', False),
                
                # åŸå§‹æ•°æ®
                raw_html=tweet_html
            )
            
            return tweet_data
            
        except Exception as e:
            self.logger.error(f"æå–å•æ¡æ¨æ–‡å¤±è´¥: {e}")
            return None
    
    async def _extract_tweet_id(self, tweet_element) -> Optional[str]:
        """æå–æ¨æ–‡ID"""
        try:
            # æŸ¥æ‰¾åŒ…å«æ¨æ–‡é“¾æ¥çš„å…ƒç´ 
            link_elements = await tweet_element.query_selector_all('a[href*="/status/"]')
            
            for link_element in link_elements:
                href = await link_element.get_attribute('href')
                if href:
                    match = self.tweet_id_pattern.search(href)
                    if match:
                        return match.group(1)
            
            return None
            
        except Exception as e:
            self.logger.debug(f"æå–æ¨æ–‡IDå¤±è´¥: {e}")
            return None
    
    async def _extract_user_info(self, tweet_element) -> Dict[str, str]:
        """æå–ç”¨æˆ·ä¿¡æ¯"""
        try:
            user_info = {}
            
            # æå–ç”¨æˆ·å
            username_element = await tweet_element.query_selector('[data-testid="User-Name"] a')
            if username_element:
                href = await username_element.get_attribute('href')
                if href:
                    username = href.strip('/').split('/')[-1]
                    user_info['username'] = username
            
            # æå–æ˜¾ç¤ºåç§°
            display_name_element = await tweet_element.query_selector('[data-testid="User-Name"] span')
            if display_name_element:
                display_name = await display_name_element.inner_text()
                user_info['display_name'] = display_name.strip()
            
            return user_info
            
        except Exception as e:
            self.logger.debug(f"æå–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    async def _extract_tweet_content(self, tweet_element) -> str:
        """æå–æ¨æ–‡å†…å®¹"""
        try:
            # æŸ¥æ‰¾æ¨æ–‡æ–‡æœ¬å…ƒç´ 
            content_element = await tweet_element.query_selector('[data-testid="tweetText"]')
            if content_element:
                content = await content_element.inner_text()
                return self._clean_text(content)
            
            return ""
            
        except Exception as e:
            self.logger.debug(f"æå–æ¨æ–‡å†…å®¹å¤±è´¥: {e}")
            return ""
    
    async def _extract_tweet_time(self, tweet_element) -> datetime:
        """æå–æ¨æ–‡æ—¶é—´"""
        try:
            # æŸ¥æ‰¾æ—¶é—´å…ƒç´  - ä½¿ç”¨å¤šç§é€‰æ‹©å™¨
            time_selectors = [
                'time',
                '[datetime]',
                'a[href*="/status/"] time',
                '[data-testid="Time"] time'
            ]
            
            for selector in time_selectors:
                try:
                    time_element = await tweet_element.query_selector(selector)
                    if time_element:
                        # ä¼˜å…ˆä½¿ç”¨datetimeå±æ€§
                        datetime_attr = await time_element.get_attribute('datetime')
                        if datetime_attr:
                            parsed_time = self._parse_datetime(datetime_attr)
                            if parsed_time is not None:
                                return parsed_time
                        
                        # å¤‡ç”¨ï¼šä½¿ç”¨titleå±æ€§
                        title_attr = await time_element.get_attribute('title')
                        if title_attr:
                            parsed_time = self._parse_datetime(title_attr)
                            if parsed_time is not None:
                                return parsed_time
                        
                        # å¤‡ç”¨ï¼šä½¿ç”¨æ–‡æœ¬å†…å®¹
                        time_text = await time_element.inner_text()
                        if time_text:
                            parsed_time = self._parse_relative_time(time_text)
                            if parsed_time:
                                return parsed_time
                except Exception:
                    continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´ï¼Œè¿”å›å½“å‰æ—¶é—´
            self.logger.warning("æœªèƒ½æå–åˆ°æ¨æ–‡æ—¶é—´ï¼Œä½¿ç”¨å½“å‰æ—¶é—´")
            return datetime.now(timezone.utc)
            
        except Exception as e:
            self.logger.debug(f"æå–æ¨æ–‡æ—¶é—´å¤±è´¥: {e}")
            return datetime.now(timezone.utc)
    
    async def _extract_engagement_data(self, tweet_element) -> Dict[str, int]:
        """æå–äº’åŠ¨æ•°æ®"""
        try:
            engagement = {
                'likes': 0,
                'retweets': 0,
                'replies': 0,
                'quotes': 0,
                'views': 0
            }
            
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨æå–ç‚¹èµæ•°
            like_selectors = [
                '[data-testid="like"]',
                '[aria-label*="like"]',
                '[aria-label*="Like"]',
                '[data-testid="heart"]'
            ]
            
            for selector in like_selectors:
                try:
                    like_element = await tweet_element.query_selector(selector)
                    if like_element:
                        like_text = await like_element.get_attribute('aria-label') or ''
                        if like_text:
                            engagement['likes'] = self._extract_count_from_label(like_text)
                            break
                except Exception:
                    continue
            
            # æå–è¯„è®ºæ•°
            reply_selectors = [
                '[data-testid="reply"]',
                '[aria-label*="repl"]',
                '[aria-label*="Reply"]',
                '[aria-label*="comment"]'
            ]
            
            for selector in reply_selectors:
                try:
                    reply_element = await tweet_element.query_selector(selector)
                    if reply_element:
                        reply_text = await reply_element.get_attribute('aria-label') or ''
                        if reply_text:
                            engagement['replies'] = self._extract_count_from_label(reply_text)
                            break
                except Exception:
                    continue
            
            # æå–è½¬å‘æ•°
            retweet_selectors = [
                '[data-testid="retweet"]',
                '[aria-label*="retweet"]',
                '[aria-label*="Retweet"]',
                '[aria-label*="repost"]'
            ]
            
            for selector in retweet_selectors:
                try:
                    retweet_element = await tweet_element.query_selector(selector)
                    if retweet_element:
                        retweet_text = await retweet_element.get_attribute('aria-label') or ''
                        if retweet_text:
                            engagement['retweets'] = self._extract_count_from_label(retweet_text)
                            break
                except Exception:
                    continue
            
            # æå–å¼•ç”¨æ•°
            quote_selectors = [
                '[data-testid="quote"]',
                '[aria-label*="quote"]',
                '[aria-label*="Quote"]'
            ]
            
            for selector in quote_selectors:
                try:
                    quote_element = await tweet_element.query_selector(selector)
                    if quote_element:
                        quote_text = await quote_element.get_attribute('aria-label') or ''
                        if quote_text:
                            engagement['quotes'] = self._extract_count_from_label(quote_text)
                            break
                except Exception:
                    continue
            
            # æå–æµè§ˆé‡
            view_selectors = [
                '[aria-label*="view"]',
                '[aria-label*="View"]',
                '[data-testid="analytics"]'
            ]
            
            for selector in view_selectors:
                try:
                    view_element = await tweet_element.query_selector(selector)
                    if view_element:
                        view_text = await view_element.get_attribute('aria-label') or ''
                        if view_text and ('view' in view_text.lower()):
                            engagement['views'] = self._extract_count_from_label(view_text)
                            break
                except Exception:
                    continue
            
            # å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾æ‰€æœ‰äº’åŠ¨æŒ‰é’®
            if all(v == 0 for v in engagement.values()):
                action_buttons = await tweet_element.query_selector_all('[role="group"] [role="button"]')
                
                for button in action_buttons:
                    try:
                        aria_label = await button.get_attribute('aria-label')
                        if aria_label:
                            count = self._extract_count_from_label(aria_label)
                            aria_lower = aria_label.lower()
                            
                            if 'like' in aria_lower and engagement['likes'] == 0:
                                engagement['likes'] = count
                            elif ('retweet' in aria_lower or 'repost' in aria_lower) and engagement['retweets'] == 0:
                                engagement['retweets'] = count
                            elif 'repl' in aria_lower and engagement['replies'] == 0:
                                engagement['replies'] = count
                            elif 'quote' in aria_lower and engagement['quotes'] == 0:
                                engagement['quotes'] = count
                            elif 'view' in aria_lower and engagement['views'] == 0:
                                engagement['views'] = count
                    except Exception:
                        continue
            
            return engagement
            
        except Exception as e:
            self.logger.debug(f"æå–äº’åŠ¨æ•°æ®å¤±è´¥: {e}")
            return {'likes': 0, 'retweets': 0, 'replies': 0, 'quotes': 0, 'views': 0}
    
    async def _extract_media_info(self, tweet_element) -> Dict[str, List[str]]:
        """æå–åª’ä½“ä¿¡æ¯"""
        try:
            media_info = {'urls': [], 'types': []}
            
            # æŸ¥æ‰¾å›¾ç‰‡ - ä½¿ç”¨å¤šç§é€‰æ‹©å™¨
            image_selectors = [
                '[data-testid="tweetPhoto"] img',
                'img[src*="pbs.twimg.com"]',
                'div[data-testid="tweetPhoto"] img',
                '[data-testid="card.layoutLarge.media"] img',
                'img[alt*="Image"]'
            ]
            
            for selector in image_selectors:
                try:
                    img_elements = await tweet_element.query_selector_all(selector)
                    for img in img_elements:
                        src = await img.get_attribute('src')
                        if src and 'profile_images' not in src and src not in media_info['urls']:
                            # è·å–é«˜è´¨é‡å›¾ç‰‡URL
                            if 'pbs.twimg.com' in src:
                                # ç§»é™¤å°ºå¯¸é™åˆ¶ï¼Œè·å–åŸå›¾
                                high_quality_src = src.split('?')[0] + '?format=jpg&name=large'
                                media_info['urls'].append(high_quality_src)
                            else:
                                media_info['urls'].append(src)
                            media_info['types'].append('image')
                except Exception:
                    continue
            
            # æŸ¥æ‰¾è§†é¢‘
            video_selectors = [
                'video',
                '[data-testid="videoPlayer"] video',
                'div[data-testid="videoComponent"] video'
            ]
            
            for selector in video_selectors:
                try:
                    video_elements = await tweet_element.query_selector_all(selector)
                    for video in video_elements:
                        # å°è¯•è·å–è§†é¢‘æº
                        src = await video.get_attribute('src')
                        if src and src not in media_info['urls']:
                            media_info['urls'].append(src)
                            media_info['types'].append('video')
                        
                        # å°è¯•è·å–posterå›¾ç‰‡
                        poster = await video.get_attribute('poster')
                        if poster and poster not in media_info['urls']:
                            media_info['urls'].append(poster)
                            media_info['types'].append('video_thumbnail')
                except Exception:
                    continue
            
            # æŸ¥æ‰¾GIF
            gif_selectors = [
                'img[src*="tweet_video_thumb"]',
                '[data-testid="gif"] img'
            ]
            
            for selector in gif_selectors:
                try:
                    gif_elements = await tweet_element.query_selector_all(selector)
                    for gif in gif_elements:
                        src = await gif.get_attribute('src')
                        if src and src not in media_info['urls']:
                            media_info['urls'].append(src)
                            media_info['types'].append('gif')
                except Exception:
                    continue
            
            # æŸ¥æ‰¾å¤–éƒ¨é“¾æ¥çš„é¢„è§ˆå›¾
            try:
                card_img_elements = await tweet_element.query_selector_all('[data-testid="card.layoutLarge.media"] img, [data-testid="card.layoutSmall.media"] img')
                for img in card_img_elements:
                    src = await img.get_attribute('src')
                    if src and src not in media_info['urls']:
                        media_info['urls'].append(src)
                        media_info['types'].append('link_preview')
            except Exception:
                pass
            
            return media_info
            
        except Exception as e:
            self.logger.debug(f"æå–åª’ä½“ä¿¡æ¯å¤±è´¥: {e}")
            return {'urls': [], 'types': []}
    
    async def _extract_links_info(self, content: str) -> Dict[str, List[str]]:
        """æå–é“¾æ¥ã€æ ‡ç­¾ã€æåŠä¿¡æ¯"""
        try:
            links_info = {
                'urls': [],
                'hashtags': [],
                'mentions': []
            }
            
            # æå–URL
            urls = self.url_pattern.findall(content)
            links_info['urls'] = list(set(urls))  # å»é‡
            
            # æå–æ ‡ç­¾
            hashtags = self.hashtag_pattern.findall(content)
            links_info['hashtags'] = [tag[1:] for tag in set(hashtags)]  # å»æ‰#å·å¹¶å»é‡
            
            # æå–æåŠ
            mentions = self.mention_pattern.findall(content)
            links_info['mentions'] = [mention[1:] for mention in set(mentions)]  # å»æ‰@å·å¹¶å»é‡
            
            return links_info
            
        except Exception as e:
            self.logger.debug(f"æå–é“¾æ¥ä¿¡æ¯å¤±è´¥: {e}")
            return {'urls': [], 'hashtags': [], 'mentions': []}
    
    async def _detect_tweet_type(self, tweet_element, content: str) -> Dict[str, bool]:
        """æ£€æµ‹æ¨æ–‡ç±»å‹"""
        try:
            tweet_type = {
                'is_retweet': False,
                'is_reply': False,
                'is_quote': False,
                'is_thread': False
            }
            
            # æ£€æµ‹è½¬æ¨
            retweet_indicator = await tweet_element.query_selector('[data-testid="socialContext"]')
            if retweet_indicator:
                text = await retweet_indicator.inner_text()
                if 'retweeted' in text.lower() or 'reposted' in text.lower():
                    tweet_type['is_retweet'] = True
            
            # æ£€æµ‹å›å¤
            reply_indicator = await tweet_element.query_selector('[data-testid="reply"]')
            if reply_indicator or content.startswith('@'):
                tweet_type['is_reply'] = True
            
            # æ£€æµ‹å¼•ç”¨æ¨æ–‡
            quote_indicator = await tweet_element.query_selector('[data-testid="quoteTweet"]')
            if quote_indicator:
                tweet_type['is_quote'] = True
            
            # æ£€æµ‹æ¨æ–‡ä¸²ï¼ˆç®€å•æ£€æµ‹ï¼‰
            if 'ğŸ§µ' in content or 'thread' in content.lower() or '/1' in content:
                tweet_type['is_thread'] = True
            
            return tweet_type
            
        except Exception as e:
            self.logger.debug(f"æ£€æµ‹æ¨æ–‡ç±»å‹å¤±è´¥: {e}")
            return {'is_retweet': False, 'is_reply': False, 'is_quote': False, 'is_thread': False}
    
    def _extract_count_from_label(self, label: str) -> int:
        """ä»aria-labelä¸­æå–æ•°é‡"""
        try:
            if not label:
                return 0
            
            # ç§»é™¤é€—å·å’Œç©ºæ ¼
            label = label.replace(',', '').replace(' ', '').lower()
            
            # æå–æ•°å­—å’Œå•ä½
            match = re.search(r'([0-9.]+)([km]?)', label)
            if not match:
                # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥æŸ¥æ‰¾æ•°å­—
                numbers = re.findall(r'\d+', label)
                if numbers:
                    return int(numbers[0])
                return 0
            
            number = float(match.group(1))
            unit = match.group(2)
            
            if unit == 'k':
                return int(number * 1000)
            elif unit == 'm':
                return int(number * 1000000)
            else:
                return int(number)
                
        except Exception as e:
            self.logger.debug(f"è§£ææ•°é‡å¤±è´¥: {label}, é”™è¯¯: {e}")
            return 0
    
    def _parse_datetime(self, datetime_str: str) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
        if not datetime_str:
            return None
            
        # æ¸…ç†æ—¶é—´å­—ç¬¦ä¸²
        datetime_str = datetime_str.strip()
        
        # æ‰©å±•æ—¶é—´æ ¼å¼åˆ—è¡¨
        extended_formats = [
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%dT%H:%M:%S%z',
            '%Y-%m-%dT%H:%M:%S.%f%z',
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d %H:%M',
            '%m/%d/%Y %H:%M:%S',
            '%m/%d/%Y %H:%M',
            '%d/%m/%Y %H:%M:%S',
            '%d/%m/%Y %H:%M',
            '%B %d, %Y at %H:%M',
            '%b %d, %Y Â· %H:%M',
            '%b %d, %Y',
            '%B %d, %Y',
            '%Y-%m-%d',
            '%m/%d/%Y',
            '%d/%m/%Y'
        ]
        
        # åˆå¹¶åŸæœ‰æ ¼å¼å’Œæ‰©å±•æ ¼å¼
        all_formats = self.time_formats + extended_formats
        
        for fmt in all_formats:
            try:
                # è§£ææ—¶é—´å¹¶ç¡®ä¿æ—¶åŒºä¸€è‡´æ€§
                dt = datetime.strptime(datetime_str, fmt)
                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºUTC
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt
            except ValueError:
                continue
        
        # å°è¯•ä½¿ç”¨dateutilè§£æ
        try:
            from dateutil import parser
            dt = parser.parse(datetime_str)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except Exception:
            pass
        
        # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œè¿”å›None
        self.logger.warning(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {datetime_str}")
        return None
    
    def _parse_relative_time(self, time_text: str) -> Optional[datetime]:
        """è§£æç›¸å¯¹æ—¶é—´ï¼ˆå¦‚2hã€1dã€3mç­‰ï¼‰"""
        if not time_text:
            return None
            
        try:
            time_text = time_text.strip().lower()
            now = datetime.now(timezone.utc)
            
            # åŒ¹é…ç›¸å¯¹æ—¶é—´æ ¼å¼
            patterns = [
                (r'(\d+)s', 1),      # ç§’
                (r'(\d+)m', 60),     # åˆ†é’Ÿ
                (r'(\d+)h', 3600),   # å°æ—¶
                (r'(\d+)d', 86400),  # å¤©
                (r'(\d+)w', 604800), # å‘¨
            ]
            
            for pattern, multiplier in patterns:
                match = re.search(pattern, time_text)
                if match:
                    value = int(match.group(1))
                    seconds_ago = value * multiplier
                    return now - timedelta(seconds=seconds_ago)
            
            # å¤„ç†ç‰¹æ®Šæƒ…å†µ
            if 'now' in time_text or 'just now' in time_text:
                return now
            elif 'yesterday' in time_text:
                return now - timedelta(days=1)
            elif 'today' in time_text:
                return now.replace(hour=12, minute=0, second=0, microsecond=0)
            
            return None
            
        except Exception as e:
            self.logger.debug(f"è§£æç›¸å¯¹æ—¶é—´å¤±è´¥: {time_text}, é”™è¯¯: {e}")
            return None
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
        
        # HTMLè§£ç 
        text = html.unescape(text)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        # å»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()
        
        return text
    
    async def extract_user_profile(self, browser_instance: BrowserInstance) -> Optional[UserData]:
        """æå–ç”¨æˆ·èµ„æ–™ä¿¡æ¯"""
        try:
            # ç­‰å¾…ç”¨æˆ·èµ„æ–™åŠ è½½
            await browser_instance.page.wait_for_selector('[data-testid="UserName"]', timeout=10000)
            
            # æå–ç”¨æˆ·å
            username_element = await browser_instance.page.query_selector('[data-testid="UserName"] span')
            username = await username_element.inner_text() if username_element else ""
            
            # æå–æ˜¾ç¤ºåç§°
            display_name_element = await browser_instance.page.query_selector('[data-testid="UserName"] div span')
            display_name = await display_name_element.inner_text() if display_name_element else ""
            
            # æå–ç®€ä»‹
            bio_element = await browser_instance.page.query_selector('[data-testid="UserDescription"]')
            bio = await bio_element.inner_text() if bio_element else ""
            
            # æå–ç»Ÿè®¡ä¿¡æ¯
            stats = await self._extract_user_stats(browser_instance)
            
            # æå–å…¶ä»–ä¿¡æ¯
            profile_info = await self._extract_profile_info(browser_instance)
            
            user_data = UserData(
                user_id=profile_info.get('user_id', ''),
                username=username.replace('@', ''),
                display_name=display_name,
                bio=bio,
                location=profile_info.get('location', ''),
                website=profile_info.get('website', ''),
                
                followers_count=stats.get('followers', 0),
                following_count=stats.get('following', 0),
                tweets_count=stats.get('tweets', 0),
                
                verified=profile_info.get('verified', False),
                protected=profile_info.get('protected', False),
                
                profile_image_url=profile_info.get('profile_image', ''),
                banner_image_url=profile_info.get('banner_image', '')
            )
            
            return user_data
            
        except Exception as e:
            self.logger.error(f"æå–ç”¨æˆ·èµ„æ–™å¤±è´¥: {e}")
            handle_exception(e)
            return None
    
    async def _extract_user_stats(self, browser_instance: BrowserInstance) -> Dict[str, int]:
        """æå–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {'followers': 0, 'following': 0, 'tweets': 0}
            
            # æŸ¥æ‰¾ç»Ÿè®¡é“¾æ¥
            stat_links = await browser_instance.page.query_selector_all('a[href*="/followers"], a[href*="/following"]')
            
            for link in stat_links:
                href = await link.get_attribute('href')
                text = await link.inner_text()
                
                if '/followers' in href:
                    stats['followers'] = self._parse_stat_number(text)
                elif '/following' in href:
                    stats['following'] = self._parse_stat_number(text)
            
            return stats
            
        except Exception as e:
            self.logger.debug(f"æå–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: {e}")
            return {'followers': 0, 'following': 0, 'tweets': 0}
    
    async def _extract_profile_info(self, browser_instance: BrowserInstance) -> Dict[str, Any]:
        """æå–èµ„æ–™ä¿¡æ¯"""
        try:
            profile_info = {}
            
            # æå–å¤´åƒ
            avatar_element = await browser_instance.page.query_selector('[data-testid="UserAvatar-Container-unknown"] img')
            if avatar_element:
                src = await avatar_element.get_attribute('src')
                if src:
                    profile_info['profile_image'] = src
            
            # æ£€æµ‹è®¤è¯çŠ¶æ€
            verified_element = await browser_instance.page.query_selector('[data-testid="icon-verified"]')
            profile_info['verified'] = verified_element is not None
            
            # æ£€æµ‹ä¿æŠ¤çŠ¶æ€
            protected_element = await browser_instance.page.query_selector('[data-testid="icon-lock"]')
            profile_info['protected'] = protected_element is not None
            
            return profile_info
            
        except Exception as e:
            self.logger.debug(f"æå–èµ„æ–™ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def _parse_stat_number(self, text: str) -> int:
        """è§£æç»Ÿè®¡æ•°å­—"""
        try:
            # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼Œä¿ç•™Kã€M
            clean_text = re.sub(r'[^\d\.KM]', '', text.upper())
            
            if 'K' in clean_text:
                number = float(clean_text.replace('K', ''))
                return int(number * 1000)
            elif 'M' in clean_text:
                number = float(clean_text.replace('M', ''))
                return int(number * 1000000)
            else:
                return int(float(clean_text)) if clean_text else 0
                
        except:
            return 0
    
    def validate_tweet_data(self, tweet_data: TweetData) -> bool:
        """éªŒè¯æ¨æ–‡æ•°æ®"""
        try:
            # åŸºæœ¬å­—æ®µéªŒè¯
            if not tweet_data.tweet_id or not tweet_data.username:
                return False
            
            # å†…å®¹é•¿åº¦éªŒè¯
            if len(tweet_data.content) > 10000:  # Twitteræœ€å¤§é•¿åº¦é™åˆ¶
                return False
            
            # æ—¶é—´éªŒè¯
            current_time = datetime.now(timezone.utc)
            tweet_time = tweet_data.created_at
            # ç¡®ä¿æ—¶åŒºä¸€è‡´æ€§
            if tweet_time.tzinfo is None:
                tweet_time = tweet_time.replace(tzinfo=timezone.utc)
            if tweet_time > current_time:
                return False
            
            # äº’åŠ¨æ•°æ®éªŒè¯
            if any(count < 0 for count in [
                tweet_data.likes_count, tweet_data.retweets_count, 
                tweet_data.replies_count, tweet_data.quotes_count
            ]):
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"éªŒè¯æ¨æ–‡æ•°æ®å¤±è´¥: {e}")
            return False
    
    def filter_tweets(self, tweets: List[TweetData], 
                     filters: Dict[str, Any]) -> List[TweetData]:
        """è¿‡æ»¤æ¨æ–‡"""
        try:
            filtered_tweets = []
            
            for tweet in tweets:
                # éªŒè¯æ•°æ®
                if not self.validate_tweet_data(tweet):
                    continue
                
                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                if self._apply_filters(tweet, filters):
                    filtered_tweets.append(tweet)
            
            return filtered_tweets
            
        except Exception as e:
            self.logger.error(f"è¿‡æ»¤æ¨æ–‡å¤±è´¥: {e}")
            return tweets
    
    def _apply_filters(self, tweet: TweetData, filters: Dict[str, Any]) -> bool:
        """åº”ç”¨è¿‡æ»¤æ¡ä»¶"""
        try:
            # æœ€å°ç‚¹èµæ•°
            if 'min_likes' in filters and tweet.likes_count < filters['min_likes']:
                return False
            
            # æœ€å°è½¬å‘æ•°
            if 'min_retweets' in filters and tweet.retweets_count < filters['min_retweets']:
                return False
            
            # å†…å®¹é•¿åº¦
            if 'min_content_length' in filters and len(tweet.content) < filters['min_content_length']:
                return False
            
            # æ’é™¤è½¬æ¨
            if filters.get('exclude_retweets', False) and tweet.is_retweet:
                return False
            
            # æ’é™¤å›å¤
            if filters.get('exclude_replies', False) and tweet.is_reply:
                return False
            
            # å¿…é¡»åŒ…å«åª’ä½“
            if filters.get('require_media', False) and not tweet.has_media:
                return False
            
            # å…³é”®è¯è¿‡æ»¤
            if 'keywords' in filters:
                keywords = filters['keywords']
                if isinstance(keywords, str):
                    keywords = [keywords]
                
                content_lower = tweet.content.lower()
                if not any(keyword.lower() in content_lower for keyword in keywords):
                    return False
            
            return True
            
        except Exception as e:
            self.logger.debug(f"åº”ç”¨è¿‡æ»¤æ¡ä»¶å¤±è´¥: {e}")
            return True


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import asyncio
    from browser_manager import BrowserManager
    
    async def test_data_extractor():
        extractor = DataExtractor()
        
        async with BrowserManager() as browser_manager:
            instance = await browser_manager.get_available_instance()
            if instance:
                # å¯¼èˆªåˆ°Twitter
                success = await browser_manager.navigate_to_page(instance, "https://twitter.com/elonmusk")
                if success:
                    # æå–æ¨æ–‡
                    tweets = await extractor.extract_tweets_from_page(instance, max_tweets=10)
                    print(f"æå–äº† {len(tweets)} æ¡æ¨æ–‡")
                    
                    # æå–ç”¨æˆ·èµ„æ–™
                    user_data = await extractor.extract_user_profile(instance)
                    if user_data:
                        print(f"ç”¨æˆ·: {user_data.display_name} (@{user_data.username})")
                
                await browser_manager.release_instance(instance)
    
    # è¿è¡Œæµ‹è¯•
    # asyncio.run(test_data_extractor())