#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆæœ¬çš„æ»šåŠ¨æµ‹è¯•è„šæœ¬
åŸºäºè°ƒè¯•å‘ç°çš„é—®é¢˜è¿›è¡Œä¿®å¤
"""

import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from ads_browser_launcher import AdsPowerLauncher
from twitter_parser import TwitterParser

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# AdsPoweré…ç½®
ADS_POWER_CONFIG = {
    'user_id': 'k11p9ypc',
    'open_tabs': 1,
    'launch_args': [],
    'headless': False,
    'disable_password_filling': False,
    'clear_cache_after_closing': False,
    'enable_password_saving': False
}

async def test_fixed_scroll():
    """æµ‹è¯•ä¿®å¤åçš„æ»šåŠ¨åŠŸèƒ½"""
    launcher = None
    parser = None
    
    try:
        # å¯åŠ¨æµè§ˆå™¨
        logger.info("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        launcher = AdsPowerLauncher(ADS_POWER_CONFIG)
        browser_info = launcher.start_browser()
        launcher.wait_for_browser_ready()
        debug_port = launcher.get_debug_port()
        logger.info(f"âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼Œè°ƒè¯•ç«¯å£: {debug_port}")
        
        # åˆå§‹åŒ–TwitterParser
        logger.info("ğŸ”§ åˆå§‹åŒ–TwitterParser...")
        parser = TwitterParser(debug_port=debug_port)
        await parser.initialize()
        logger.info("âœ… TwitterParseråˆå§‹åŒ–å®Œæˆ")
        
        # å¯¼èˆªåˆ°Elon Muskçš„é¡µé¢ï¼ˆè°ƒè¯•è„šæœ¬æ˜¾ç¤ºè¿™ä¸ªé¡µé¢æœ‰æ¨æ–‡ï¼‰
        logger.info("ğŸ”„ å¯¼èˆªåˆ°@elonmuské¡µé¢...")
        try:
            await parser.navigate_to_profile('elonmusk')
            logger.info("âœ… æˆåŠŸå¯¼èˆªåˆ°ç”¨æˆ·é¡µé¢")
        except Exception as nav_error:
            logger.warning(f"å¯¼èˆªå¤±è´¥: {nav_error}ï¼Œå°è¯•ç›´æ¥è®¿é—®")
            await parser.page.goto('https://x.com/elonmusk', wait_until='domcontentloaded')
            await asyncio.sleep(5)
        
        # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        logger.info("â³ ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½...")
        await asyncio.sleep(10)
        
        # æ£€æŸ¥åˆå§‹æ¨æ–‡æ•°é‡
        initial_tweets = await parser.page.query_selector_all('[data-testid="tweet"]')
        logger.info(f"ğŸ“Š åˆå§‹æ¨æ–‡æ•°é‡: {len(initial_tweets)}")
        
        if len(initial_tweets) == 0:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°åˆå§‹æ¨æ–‡ï¼Œå¯èƒ½éœ€è¦æ›´é•¿ç­‰å¾…æ—¶é—´")
            await asyncio.sleep(10)
            initial_tweets = await parser.page.query_selector_all('[data-testid="tweet"]')
            logger.info(f"ğŸ“Š é‡æ–°æ£€æŸ¥æ¨æ–‡æ•°é‡: {len(initial_tweets)}")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ¨æ–‡ï¼Œå°è¯•æ»šåŠ¨ä¸€ä¸‹æ¿€æ´»é¡µé¢
        if len(initial_tweets) == 0:
            logger.info("ğŸ”„ å°è¯•æ»šåŠ¨æ¿€æ´»é¡µé¢...")
            await parser.page.evaluate('window.scrollBy(0, 500)')
            await asyncio.sleep(3)
            await parser.page.evaluate('window.scrollBy(0, -500)')
            await asyncio.sleep(3)
            initial_tweets = await parser.page.query_selector_all('[data-testid="tweet"]')
            logger.info(f"ğŸ“Š æ»šåŠ¨åæ¨æ–‡æ•°é‡: {len(initial_tweets)}")
        
        # æµ‹è¯•ä¿®å¤åçš„æ»šåŠ¨åŠŸèƒ½
        target_tweets = 20
        logger.info(f"ğŸ¯ å¼€å§‹æµ‹è¯•æ»šåŠ¨åŠ è½½ï¼Œç›®æ ‡: {target_tweets} æ¡æ¨æ–‡")
        
        # ä½¿ç”¨ä¿®å¤åçš„æ»šåŠ¨é€»è¾‘
        scroll_attempts = 0
        max_scroll_attempts = 10
        last_tweet_count = len(initial_tweets)
        stagnant_count = 0
        
        while scroll_attempts < max_scroll_attempts:
            # è·å–å½“å‰æ¨æ–‡æ•°é‡
            current_tweets = await parser.page.query_selector_all('[data-testid="tweet"]')
            current_count = len(current_tweets)
            
            logger.info(f"ğŸ“ˆ æ»šåŠ¨å°è¯• {scroll_attempts + 1}/{max_scroll_attempts}ï¼Œå½“å‰æ¨æ–‡: {current_count}")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if current_count >= target_tweets:
                logger.info(f"ğŸ‰ è¾¾åˆ°ç›®æ ‡æ¨æ–‡æ•°é‡: {current_count}/{target_tweets}")
                break
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¨æ–‡åŠ è½½
            if current_count == last_tweet_count:
                stagnant_count += 1
                logger.info(f"â¸ï¸ æ¨æ–‡æ•°é‡æœªå¢åŠ ï¼Œåœæ»æ¬¡æ•°: {stagnant_count}")
            else:
                stagnant_count = 0
                logger.info(f"ğŸ“ˆ æ–°å¢æ¨æ–‡: {current_count - last_tweet_count}")
            
            last_tweet_count = current_count
            
            # å¦‚æœè¿ç»­åœæ»å¤ªå¤šæ¬¡ï¼Œåœæ­¢æ»šåŠ¨
            if stagnant_count >= 5:
                logger.warning("âš ï¸ è¿ç»­å¤šæ¬¡æ— æ–°æ¨æ–‡ï¼Œåœæ­¢æ»šåŠ¨")
                break
            
            # æ‰§è¡Œæ»šåŠ¨
            scroll_distance = 1000 if stagnant_count < 3 else 2000
            logger.info(f"ğŸ“œ æ»šåŠ¨è·ç¦»: {scroll_distance}px")
            
            await parser.page.evaluate(f'window.scrollBy(0, {scroll_distance})')
            
            # ç­‰å¾…å†…å®¹åŠ è½½
            wait_time = 2 if stagnant_count < 3 else 4
            await asyncio.sleep(wait_time)
            
            scroll_attempts += 1
        
        # æœ€ç»ˆç»Ÿè®¡
        final_tweets = await parser.page.query_selector_all('[data-testid="tweet"]')
        final_count = len(final_tweets)
        
        logger.info(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
        logger.info(f"  åˆå§‹æ¨æ–‡æ•°é‡: {len(initial_tweets)}")
        logger.info(f"  æœ€ç»ˆæ¨æ–‡æ•°é‡: {final_count}")
        logger.info(f"  æ–°å¢æ¨æ–‡æ•°é‡: {final_count - len(initial_tweets)}")
        logger.info(f"  æ»šåŠ¨æ¬¡æ•°: {scroll_attempts}")
        logger.info(f"  ç›®æ ‡å®Œæˆåº¦: {final_count}/{target_tweets} ({final_count/target_tweets*100:.1f}%)")
        
        # æµ‹è¯•æ¨æ–‡å†…å®¹æå–
        if final_count > 0:
            logger.info(f"\nğŸ” æµ‹è¯•æ¨æ–‡å†…å®¹æå–ï¼ˆå‰3æ¡ï¼‰:")
            for i, tweet_element in enumerate(final_tweets[:3]):
                try:
                    # æå–æ¨æ–‡æ–‡æœ¬
                    text_element = await tweet_element.query_selector('[data-testid="tweetText"]')
                    if text_element:
                        text_content = await text_element.inner_text()
                        logger.info(f"  æ¨æ–‡ {i+1}: {text_content[:100]}...")
                    else:
                        logger.info(f"  æ¨æ–‡ {i+1}: æ— æ³•æå–æ–‡æœ¬å†…å®¹")
                except Exception as e:
                    logger.warning(f"  æ¨æ–‡ {i+1}: æå–å¤±è´¥ - {e}")
        
        if final_count >= target_tweets * 0.8:
            logger.info("âœ… æ»šåŠ¨æµ‹è¯•æˆåŠŸï¼")
        else:
            logger.warning("âš ï¸ æ»šåŠ¨æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼Œä½†æœªè¾¾åˆ°é¢„æœŸç›®æ ‡")
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
    finally:
        # æ¸…ç†èµ„æº
        if parser:
            try:
                await parser.close()
                logger.info("âœ… TwitterParserå·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­TwitterParseræ—¶å‡ºé”™: {e}")
        
        if launcher:
            try:
                launcher.stop_browser()
                logger.info("âœ… æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(test_fixed_scroll())