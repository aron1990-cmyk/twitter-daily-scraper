#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨æ–‡é‡‡é›†åŠŸèƒ½ç»¼åˆæµ‹è¯•ç”¨ä¾‹
æµ‹è¯•å„ç§é‡‡é›†åœºæ™¯å’Œè¾¹ç•Œæƒ…å†µ
"""

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import List, Dict, Any
import pytest

# å¯¼å…¥æµ‹è¯•æ‰€éœ€çš„æ¨¡å—
from ads_browser_launcher import AdsPowerLauncher
from twitter_parser import TwitterParser
from human_behavior_simulator import HumanBehaviorSimulator
from config import BROWSER_CONFIG

class ComprehensiveScrapingTest:
    """æ¨æ–‡é‡‡é›†ç»¼åˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.logger = self.setup_logging()
        self.test_results = []
        self.browser_launcher = None
        self.parser = None
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('test_comprehensive_scraping.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    async def setup_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        try:
            self.browser_launcher = AdsPowerLauncher()
            browser_info = self.browser_launcher.start_browser()
            
            if not browser_info:
                raise Exception("æµè§ˆå™¨å¯åŠ¨å¤±è´¥")
            
            debug_port = browser_info.get('ws', {}).get('puppeteer')
            if not debug_port:
                raise Exception("æ— æ³•è·å–æµè§ˆå™¨è°ƒè¯•ç«¯å£")
            
            self.parser = TwitterParser(debug_port)
            await self.parser.initialize()
            
            self.logger.info("âœ… æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def cleanup_browser(self):
        """æ¸…ç†æµè§ˆå™¨èµ„æº"""
        try:
            if self.parser:
                await self.parser.close()
            if self.browser_launcher:
                self.browser_launcher.close_browser()
            self.logger.info("âœ… æµè§ˆå™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.error(f"âŒ æµè§ˆå™¨æ¸…ç†å¤±è´¥: {e}")
    
    def record_test_result(self, test_name: str, success: bool, 
                          expected_count: int, actual_count: int, 
                          duration: float, error_msg: str = None):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        result = {
            'test_name': test_name,
            'success': success,
            'expected_count': expected_count,
            'actual_count': actual_count,
            'duration': duration,
            'timestamp': datetime.now().isoformat(),
            'error_msg': error_msg
        }
        self.test_results.append(result)
        
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        self.logger.info(f"{status} {test_name}: æœŸæœ›{expected_count}æ¡ï¼Œå®é™…{actual_count}æ¡ï¼Œè€—æ—¶{duration:.2f}ç§’")
        if error_msg:
            self.logger.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
    
    async def test_user_profile_scraping(self):
        """æµ‹è¯•ç”¨æˆ·ä¸ªäººèµ„æ–™é¡µé¢é‡‡é›†"""
        test_cases = [
            {'username': 'elonmusk', 'max_tweets': 5, 'description': 'çŸ¥åç”¨æˆ·å°‘é‡æ¨æ–‡'},
            {'username': 'elonmusk', 'max_tweets': 20, 'description': 'çŸ¥åç”¨æˆ·ä¸­ç­‰æ•°é‡æ¨æ–‡'},
            {'username': 'elonmusk', 'max_tweets': 50, 'description': 'çŸ¥åç”¨æˆ·å¤§é‡æ¨æ–‡'},
        ]
        
        for case in test_cases:
            start_time = time.time()
            try:
                self.logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {case['description']}")
                
                tweets = await self.parser.scrape_user_tweets(
                    username=case['username'],
                    max_tweets=case['max_tweets']
                )
                
                duration = time.time() - start_time
                actual_count = len(tweets)
                
                # åˆ¤æ–­æµ‹è¯•æ˜¯å¦æˆåŠŸï¼ˆå…è®¸ä¸€å®šçš„è¯¯å·®èŒƒå›´ï¼‰
                success = actual_count >= min(case['max_tweets'] * 0.6, 5)  # è‡³å°‘60%æˆ–5æ¡
                
                self.record_test_result(
                    test_name=f"ç”¨æˆ·é‡‡é›†-{case['description']}",
                    success=success,
                    expected_count=case['max_tweets'],
                    actual_count=actual_count,
                    duration=duration
                )
                
                # éªŒè¯æ¨æ–‡æ•°æ®è´¨é‡
                if tweets:
                    self.validate_tweet_data_quality(tweets, f"ç”¨æˆ·é‡‡é›†-{case['description']}")
                
            except Exception as e:
                duration = time.time() - start_time
                self.record_test_result(
                    test_name=f"ç”¨æˆ·é‡‡é›†-{case['description']}",
                    success=False,
                    expected_count=case['max_tweets'],
                    actual_count=0,
                    duration=duration,
                    error_msg=str(e)
                )
    
    async def test_keyword_search_scraping(self):
        """æµ‹è¯•å…³é”®è¯æœç´¢é‡‡é›†"""
        test_cases = [
            {'keyword': 'AI', 'max_tweets': 10, 'description': 'çƒ­é—¨å…³é”®è¯'},
            {'keyword': 'Python', 'max_tweets': 15, 'description': 'æŠ€æœ¯å…³é”®è¯'},
            {'keyword': 'äººå·¥æ™ºèƒ½', 'max_tweets': 8, 'description': 'ä¸­æ–‡å…³é”®è¯'},
            {'keyword': 'veryrareuncommonkeyword123', 'max_tweets': 5, 'description': 'ç½•è§å…³é”®è¯'},
        ]
        
        for case in test_cases:
            start_time = time.time()
            try:
                self.logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {case['description']}")
                
                tweets = await self.parser.scrape_keyword_tweets(
                    keyword=case['keyword'],
                    max_tweets=case['max_tweets']
                )
                
                duration = time.time() - start_time
                actual_count = len(tweets)
                
                # å¯¹äºç½•è§å…³é”®è¯ï¼Œå…è®¸ç»“æœä¸º0
                if case['keyword'] == 'veryrareuncommonkeyword123':
                    success = True  # ç½•è§å…³é”®è¯æµ‹è¯•ä¸»è¦éªŒè¯ä¸ä¼šå´©æºƒ
                else:
                    success = actual_count >= min(case['max_tweets'] * 0.4, 3)  # è‡³å°‘40%æˆ–3æ¡
                
                self.record_test_result(
                    test_name=f"å…³é”®è¯é‡‡é›†-{case['description']}",
                    success=success,
                    expected_count=case['max_tweets'],
                    actual_count=actual_count,
                    duration=duration
                )
                
                # éªŒè¯æ¨æ–‡æ•°æ®è´¨é‡
                if tweets:
                    self.validate_tweet_data_quality(tweets, f"å…³é”®è¯é‡‡é›†-{case['description']}")
                
            except Exception as e:
                duration = time.time() - start_time
                self.record_test_result(
                    test_name=f"å…³é”®è¯é‡‡é›†-{case['description']}",
                    success=False,
                    expected_count=case['max_tweets'],
                    actual_count=0,
                    duration=duration,
                    error_msg=str(e)
                )
    
    async def test_user_keyword_combined_scraping(self):
        """æµ‹è¯•ç”¨æˆ·+å…³é”®è¯ç»„åˆé‡‡é›†"""
        test_cases = [
            {'username': 'elonmusk', 'keyword': 'Tesla', 'max_tweets': 8, 'description': 'ç”¨æˆ·ç‰¹å®šå…³é”®è¯'},
            {'username': 'elonmusk', 'keyword': 'AI', 'max_tweets': 5, 'description': 'ç”¨æˆ·AIç›¸å…³æ¨æ–‡'},
        ]
        
        for case in test_cases:
            start_time = time.time()
            try:
                self.logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {case['description']}")
                
                tweets = await self.parser.scrape_user_keyword_tweets(
                    username=case['username'],
                    keyword=case['keyword'],
                    max_tweets=case['max_tweets']
                )
                
                duration = time.time() - start_time
                actual_count = len(tweets)
                
                # ç»„åˆæœç´¢å¯èƒ½ç»“æœè¾ƒå°‘ï¼Œé™ä½æœŸæœ›
                success = actual_count >= min(case['max_tweets'] * 0.3, 2)  # è‡³å°‘30%æˆ–2æ¡
                
                self.record_test_result(
                    test_name=f"ç»„åˆé‡‡é›†-{case['description']}",
                    success=success,
                    expected_count=case['max_tweets'],
                    actual_count=actual_count,
                    duration=duration
                )
                
                # éªŒè¯æ¨æ–‡æ•°æ®è´¨é‡
                if tweets:
                    self.validate_tweet_data_quality(tweets, f"ç»„åˆé‡‡é›†-{case['description']}")
                
            except Exception as e:
                duration = time.time() - start_time
                self.record_test_result(
                    test_name=f"ç»„åˆé‡‡é›†-{case['description']}",
                    success=False,
                    expected_count=case['max_tweets'],
                    actual_count=0,
                    duration=duration,
                    error_msg=str(e)
                )
    
    async def test_edge_cases(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        edge_cases = [
            {'test_type': 'zero_tweets', 'max_tweets': 0, 'description': 'é›¶æ¨æ–‡è¯·æ±‚'},
            {'test_type': 'large_number', 'max_tweets': 100, 'description': 'å¤§æ•°é‡æ¨æ–‡è¯·æ±‚'},
            {'test_type': 'invalid_user', 'username': 'thisuserdoesnotexist12345', 'max_tweets': 5, 'description': 'ä¸å­˜åœ¨çš„ç”¨æˆ·'},
        ]
        
        for case in edge_cases:
            start_time = time.time()
            try:
                self.logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•è¾¹ç•Œæƒ…å†µ: {case['description']}")
                
                if case['test_type'] == 'zero_tweets':
                    tweets = await self.parser.scrape_user_tweets(
                        username='elonmusk',
                        max_tweets=case['max_tweets']
                    )
                elif case['test_type'] == 'large_number':
                    tweets = await self.parser.scrape_user_tweets(
                        username='elonmusk',
                        max_tweets=case['max_tweets']
                    )
                elif case['test_type'] == 'invalid_user':
                    tweets = await self.parser.scrape_user_tweets(
                        username=case['username'],
                        max_tweets=case['max_tweets']
                    )
                
                duration = time.time() - start_time
                actual_count = len(tweets)
                
                # è¾¹ç•Œæƒ…å†µçš„æˆåŠŸæ ‡å‡†
                if case['test_type'] == 'zero_tweets':
                    success = actual_count == 0
                elif case['test_type'] == 'large_number':
                    success = actual_count >= 20  # å¤§æ•°é‡è¯·æ±‚è‡³å°‘åº”è¯¥è·å¾—20æ¡
                elif case['test_type'] == 'invalid_user':
                    success = actual_count == 0  # ä¸å­˜åœ¨çš„ç”¨æˆ·åº”è¯¥è¿”å›0æ¡
                
                self.record_test_result(
                    test_name=f"è¾¹ç•Œæµ‹è¯•-{case['description']}",
                    success=success,
                    expected_count=case['max_tweets'],
                    actual_count=actual_count,
                    duration=duration
                )
                
            except Exception as e:
                duration = time.time() - start_time
                # å¯¹äºæŸäº›è¾¹ç•Œæƒ…å†µï¼Œå¼‚å¸¸æ˜¯é¢„æœŸçš„
                if case['test_type'] == 'invalid_user':
                    success = True  # ä¸å­˜åœ¨ç”¨æˆ·æŠ›å¼‚å¸¸æ˜¯æ­£å¸¸çš„
                else:
                    success = False
                
                self.record_test_result(
                    test_name=f"è¾¹ç•Œæµ‹è¯•-{case['description']}",
                    success=success,
                    expected_count=case['max_tweets'],
                    actual_count=0,
                    duration=duration,
                    error_msg=str(e)
                )
    
    def validate_tweet_data_quality(self, tweets: List[Dict], test_name: str):
        """éªŒè¯æ¨æ–‡æ•°æ®è´¨é‡"""
        quality_issues = []
        
        for i, tweet in enumerate(tweets):
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['username', 'content', 'likes', 'comments', 'retweets']
            for field in required_fields:
                if field not in tweet or tweet[field] is None:
                    quality_issues.append(f"æ¨æ–‡{i+1}ç¼ºå°‘å­—æ®µ: {field}")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            if 'likes' in tweet and not isinstance(tweet['likes'], int):
                quality_issues.append(f"æ¨æ–‡{i+1}ç‚¹èµæ•°ç±»å‹é”™è¯¯")
            
            if 'content' in tweet and not isinstance(tweet['content'], str):
                quality_issues.append(f"æ¨æ–‡{i+1}å†…å®¹ç±»å‹é”™è¯¯")
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
            if 'content' in tweet and not tweet['content'].strip():
                quality_issues.append(f"æ¨æ–‡{i+1}å†…å®¹ä¸ºç©º")
        
        if quality_issues:
            self.logger.warning(f"âš ï¸ {test_name} æ•°æ®è´¨é‡é—®é¢˜: {'; '.join(quality_issues[:5])}")
        else:
            self.logger.info(f"âœ… {test_name} æ•°æ®è´¨é‡è‰¯å¥½")
    
    async def test_performance_metrics(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
        self.logger.info("ğŸ§ª å¼€å§‹æ€§èƒ½æµ‹è¯•")
        
        # æµ‹è¯•å•æ¡æ¨æ–‡å¹³å‡å¤„ç†æ—¶é—´
        start_time = time.time()
        tweets = await self.parser.scrape_user_tweets(
            username='elonmusk',
            max_tweets=10
        )
        duration = time.time() - start_time
        
        if tweets:
            avg_time_per_tweet = duration / len(tweets)
            self.logger.info(f"ğŸ“Š å¹³å‡æ¯æ¡æ¨æ–‡å¤„ç†æ—¶é—´: {avg_time_per_tweet:.2f}ç§’")
            
            # æ€§èƒ½æ ‡å‡†ï¼šæ¯æ¡æ¨æ–‡å¤„ç†æ—¶é—´ä¸è¶…è¿‡5ç§’
            performance_ok = avg_time_per_tweet <= 5.0
            
            self.record_test_result(
                test_name="æ€§èƒ½æµ‹è¯•-å¤„ç†é€Ÿåº¦",
                success=performance_ok,
                expected_count=10,
                actual_count=len(tweets),
                duration=duration
            )
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result['success'])
        failed_tests = total_tests - passed_tests
        
        report = {
            'test_summary': {
                'total_tests': total_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': f"{(passed_tests/total_tests*100):.1f}%" if total_tests > 0 else "0%",
                'test_time': datetime.now().isoformat()
            },
            'detailed_results': self.test_results
        }
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        with open('comprehensive_scraping_test_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°æ‘˜è¦
        self.logger.info("\n" + "="*50)
        self.logger.info("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
        self.logger.info("="*50)
        self.logger.info(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        self.logger.info(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
        self.logger.info(f"å¤±è´¥æµ‹è¯•: {failed_tests}")
        self.logger.info(f"æˆåŠŸç‡: {(passed_tests/total_tests*100):.1f}%")
        self.logger.info("="*50)
        
        return report
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹æ¨æ–‡é‡‡é›†åŠŸèƒ½ç»¼åˆæµ‹è¯•")
        
        # åˆå§‹åŒ–æµè§ˆå™¨
        if not await self.setup_browser():
            self.logger.error("âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
        
        try:
            # è¿è¡Œå„ç±»æµ‹è¯•
            await self.test_user_profile_scraping()
            await asyncio.sleep(2)  # æµ‹è¯•é—´éš”
            
            await self.test_keyword_search_scraping()
            await asyncio.sleep(2)
            
            await self.test_user_keyword_combined_scraping()
            await asyncio.sleep(2)
            
            await self.test_edge_cases()
            await asyncio.sleep(2)
            
            await self.test_performance_metrics()
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        
        finally:
            # æ¸…ç†èµ„æº
            await self.cleanup_browser()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_test_report()
            
            self.logger.info("âœ… æµ‹è¯•å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° comprehensive_scraping_test_report.json")
            
            return report

# ä¸»å‡½æ•°
async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test_runner = ComprehensiveScrapingTest()
    await test_runner.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())