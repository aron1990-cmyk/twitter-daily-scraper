#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘ç«¯åŒæ­¥æ¨¡å— - æ”¯æŒGoogle Sheetså’Œé£ä¹¦æ–‡æ¡£APIåŒæ­¥
"""

import requests
import json
import time
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
import asyncio

try:
    import gspread
    from google.oauth2.service_account import Credentials
except ImportError:
    gspread = None
    Credentials = None

try:
    import requests
except ImportError:
    requests = None

class CloudSyncManager:
    """
    äº‘ç«¯åŒæ­¥ç®¡ç†å™¨
    æ”¯æŒGoogle Sheetså’Œé£ä¹¦æ–‡æ¡£çš„æ•°æ®åŒæ­¥
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger('CloudSync')
        self.google_client = None
        self.feishu_config = self.config.get('feishu', {})
        
    def setup_google_sheets(self, credentials_file: str, scopes: List[str] = None) -> bool:
        """
        è®¾ç½®Google Sheetsè¿æ¥
        
        Args:
            credentials_file: GoogleæœåŠ¡è´¦å·å‡­è¯æ–‡ä»¶è·¯å¾„
            scopes: APIæƒé™èŒƒå›´
            
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if not gspread or not Credentials:
            self.logger.error("Google Sheetsä¾èµ–æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install gspread google-auth")
            return False
            
        try:
            if scopes is None:
                scopes = [
                    'https://www.googleapis.com/auth/spreadsheets',
                    'https://www.googleapis.com/auth/drive'
                ]
            
            credentials = Credentials.from_service_account_file(
                credentials_file, scopes=scopes
            )
            self.google_client = gspread.authorize(credentials)
            self.logger.info("Google Sheetsè¿æ¥è®¾ç½®æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error(f"Google Sheetsè®¾ç½®å¤±è´¥: {e}")
            return False
    
    def sync_to_google_sheets(self, data: List[Dict[str, Any]], 
                             spreadsheet_id: str, 
                             worksheet_name: str = None) -> bool:
        """
        åŒæ­¥æ•°æ®åˆ°Google Sheets
        
        Args:
            data: è¦åŒæ­¥çš„æ•°æ®
            spreadsheet_id: Googleè¡¨æ ¼ID
            worksheet_name: å·¥ä½œè¡¨åç§°
            
        Returns:
            æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        if not self.google_client:
            self.logger.error("Google Sheetsæœªåˆå§‹åŒ–")
            return False
            
        try:
            # æ‰“å¼€è¡¨æ ¼
            spreadsheet = self.google_client.open_by_key(spreadsheet_id)
            
            # è·å–æˆ–åˆ›å»ºå·¥ä½œè¡¨
            if worksheet_name:
                try:
                    worksheet = spreadsheet.worksheet(worksheet_name)
                except:
                    worksheet = spreadsheet.add_worksheet(
                        title=worksheet_name, rows=1000, cols=20
                    )
            else:
                worksheet = spreadsheet.sheet1
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            worksheet.clear()
            
            if not data:
                self.logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
                return True
            
            # å‡†å¤‡è¡¨å¤´
            headers = [
                'åºå·', 'ç”¨æˆ·å', 'æ¨æ–‡å†…å®¹', 'å‘å¸ƒæ—¶é—´', 'ç‚¹èµæ•°', 
                'è¯„è®ºæ•°', 'è½¬å‘æ•°', 'é“¾æ¥', 'æ ‡ç­¾', 'ç­›é€‰çŠ¶æ€'
            ]
            
            # å‡†å¤‡æ•°æ®è¡Œ
            rows = [headers]
            for i, tweet in enumerate(data, 1):
                row = [
                    i,
                    tweet.get('username', ''),
                    tweet.get('content', ''),
                    tweet.get('timestamp', ''),
                    tweet.get('likes', 0),
                    tweet.get('comments', 0),
                    tweet.get('retweets', 0),
                    tweet.get('link', ''),
                    ', '.join(tweet.get('tags', [])),
                    tweet.get('filter_status', '')
                ]
                rows.append(row)
            
            # æ‰¹é‡æ›´æ–°æ•°æ®
            worksheet.update('A1', rows)
            
            # æ·»åŠ åŒæ­¥æ—¶é—´æˆ³
            timestamp_cell = f"A{len(rows) + 2}"
            worksheet.update(timestamp_cell, f"æœ€ååŒæ­¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            self.logger.info(f"æˆåŠŸåŒæ­¥ {len(data)} æ¡æ•°æ®åˆ°Google Sheets")
            return True
            
        except Exception as e:
            self.logger.error(f"Google SheetsåŒæ­¥å¤±è´¥: {e}")
            return False
    
    def setup_feishu(self, app_id: str, app_secret: str) -> bool:
        """
        è®¾ç½®é£ä¹¦åº”ç”¨é…ç½®
        
        Args:
            app_id: é£ä¹¦åº”ç”¨ID
            app_secret: é£ä¹¦åº”ç”¨å¯†é’¥
            
        Returns:
            æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if not requests:
            self.logger.error("requestsä¾èµ–æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install requests")
            return False
            
        self.feishu_config = {
            'app_id': app_id,
            'app_secret': app_secret,
            'base_url': 'https://open.feishu.cn/open-apis'
        }
        self.logger.info("é£ä¹¦é…ç½®è®¾ç½®æˆåŠŸ")
        return True
    
    def get_feishu_access_token(self) -> Optional[str]:
        """
        è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ
        
        Returns:
            è®¿é—®ä»¤ç‰Œæˆ–None
        """
        print(f"ğŸ”‘ [CloudSync] å¼€å§‹è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
        
        if not self.feishu_config.get('app_id'):
            print(f"âŒ [CloudSync] é£ä¹¦é…ç½®æœªè®¾ç½®")
            self.logger.error("é£ä¹¦é…ç½®æœªè®¾ç½®")
            return None
        
        print(f"   - App ID: {self.feishu_config['app_id']}")
        print(f"   - App Secret: {self.feishu_config['app_secret'][:10]}...")
        print(f"   - Base URL: {self.feishu_config['base_url']}")
            
        try:
            url = f"{self.feishu_config['base_url']}/auth/v3/tenant_access_token/internal"
            payload = {
                'app_id': self.feishu_config['app_id'],
                'app_secret': self.feishu_config['app_secret']
            }
            
            print(f"ğŸŒ [CloudSync] å‘é€ä»¤ç‰Œè¯·æ±‚")
            print(f"   - è¯·æ±‚URL: {url}")
            print(f"   - è¯·æ±‚è½½è·: {{'app_id': '{payload['app_id']}', 'app_secret': '***'}}")
            
            response = requests.post(url, json=payload, timeout=30)
            print(f"ğŸ“Š [CloudSync] ä»¤ç‰Œè¯·æ±‚å“åº”çŠ¶æ€ç : {response.status_code}")
            
            response.raise_for_status()
            
            result = response.json()
            print(f"ğŸ“Š [CloudSync] ä»¤ç‰Œå“åº”è§£æ: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
            
            if result.get('code') == 0:
                token = result.get('tenant_access_token')
                print(f"âœ… [CloudSync] æˆåŠŸè·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ: {token[:10]}...")
                return token
            else:
                error_msg = f"è·å–é£ä¹¦ä»¤ç‰Œå¤±è´¥: {result.get('msg')}"
                print(f"âŒ [CloudSync] {error_msg}")
                self.logger.error(error_msg)
                return None
                
        except Exception as e:
            error_msg = f"è·å–é£ä¹¦ä»¤ç‰Œå¼‚å¸¸: {e}"
            print(f"âŒ [CloudSync] {error_msg}")
            self.logger.error(error_msg)
            import traceback
            print(f"   - å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def sync_to_feishu(self, data: List[Dict[str, Any]], 
                      spreadsheet_token: str, 
                      table_id: str = None,
                      max_retries: int = 3,
                      continue_on_failure: bool = True) -> bool:
        """
        åŒæ­¥æ•°æ®åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼
        
        Args:
            data: è¦åŒæ­¥çš„æ•°æ®
            spreadsheet_token: é£ä¹¦è¡¨æ ¼token
            table_id: å¤šç»´è¡¨æ ¼ID
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            continue_on_failure: å¤±è´¥æ—¶æ˜¯å¦ç»§ç»­ï¼ˆä¸æŠ›å‡ºå¼‚å¸¸ï¼‰
            
        Returns:
            æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        self.logger.info(f"ğŸš€ [CloudSync] å¼€å§‹é£ä¹¦åŒæ­¥æµç¨‹")
        self.logger.info(f"   - æ•°æ®æ¡æ•°: {len(data)}")
        self.logger.info(f"   - è¡¨æ ¼Token: {spreadsheet_token[:10]}...")
        self.logger.info(f"   - è¡¨æ ¼ID: {table_id}")
        self.logger.info(f"   - æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
        self.logger.info(f"   - å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œ: {continue_on_failure}")
        
        for attempt in range(max_retries):
            try:
                self.logger.info(f"ğŸ”‘ [CloudSync] å°è¯•è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ (ç¬¬{attempt + 1}æ¬¡)")
                access_token = self.get_feishu_access_token()
                if not access_token:
                    if attempt < max_retries - 1:
                        self.logger.warning(f"âš ï¸ [CloudSync] è·å–é£ä¹¦ä»¤ç‰Œå¤±è´¥ï¼Œ{5}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                        time.sleep(5)
                        continue
                    else:
                        if continue_on_failure:
                            self.logger.error("âŒ [CloudSync] é£ä¹¦ä»¤ç‰Œè·å–å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œä»»åŠ¡")
                            return False
                        else:
                            self.logger.error("âŒ [CloudSync] é£ä¹¦ä»¤ç‰Œè·å–å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸")
                            raise Exception("æ— æ³•è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
                
                self.logger.info(f"âœ… [CloudSync] é£ä¹¦è®¿é—®ä»¤ç‰Œè·å–æˆåŠŸ")
                result = self._execute_feishu_sync(data, spreadsheet_token, table_id, access_token)
                self.logger.info(f"ğŸ“Š [CloudSync] åŒæ­¥æ‰§è¡Œç»“æœ: {result}")
                return result
                
            except Exception as e:
                self.logger.error(f"âŒ [CloudSync] é£ä¹¦åŒæ­¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    wait_time = 10 * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                    self.logger.info(f"â³ [CloudSync] {wait_time}ç§’åé‡è¯•é£ä¹¦åŒæ­¥")
                    time.sleep(wait_time)
                else:
                    if continue_on_failure:
                        self.logger.error("âŒ [CloudSync] é£ä¹¦åŒæ­¥æœ€ç»ˆå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œä»»åŠ¡")
                        return False
                    else:
                        self.logger.error("âŒ [CloudSync] é£ä¹¦åŒæ­¥æœ€ç»ˆå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸")
                        raise e
        
        self.logger.error("âŒ [CloudSync] æ‰€æœ‰é‡è¯•å°è¯•éƒ½å·²ç”¨å°½")
        return False
    
    def _execute_feishu_sync(self, data: List[Dict[str, Any]], 
                           spreadsheet_token: str, 
                           table_id: str,
                           access_token: str) -> bool:
        """
        æ‰§è¡Œé£ä¹¦åŒæ­¥çš„æ ¸å¿ƒé€»è¾‘
        
        Args:
            data: è¦åŒæ­¥çš„æ•°æ®
            spreadsheet_token: é£ä¹¦è¡¨æ ¼token
            table_id: å¤šç»´è¡¨æ ¼ID
            access_token: è®¿é—®ä»¤ç‰Œ
            
        Returns:
            æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        try:
             self.logger.info(f"ğŸ”§ [CloudSync] å¼€å§‹æ‰§è¡Œé£ä¹¦åŒæ­¥æ ¸å¿ƒé€»è¾‘")
             self.logger.info(f"   - æ•°æ®æ¡æ•°: {len(data)}")
             self.logger.info(f"   - è¡¨æ ¼Token: {spreadsheet_token[:10]}...")
             self.logger.info(f"   - è¡¨æ ¼ID: {table_id}")
             
             # è®¾ç½®è¯·æ±‚å¤´
             headers = {
                 'Authorization': f'Bearer {access_token}',
                 'Content-Type': 'application/json'
             }
             self.logger.info(f"ğŸ”‘ [CloudSync] è¯·æ±‚å¤´è®¾ç½®å®Œæˆ")
             
             # è·å–è¡¨æ ¼å­—æ®µä¿¡æ¯ä»¥ç¡®å®šå­—æ®µç±»å‹
             self.logger.info(f"ğŸ“‹ [CloudSync] å¼€å§‹è·å–é£ä¹¦è¡¨æ ¼å­—æ®µä¿¡æ¯")
             fields_url = f"{self.feishu_config['base_url']}/bitable/v1/apps/{spreadsheet_token}/tables/{table_id}/fields"
             self.logger.info(f"   - å­—æ®µæŸ¥è¯¢URL: {fields_url}")
             
             self.logger.info(f"ğŸŒ å‘é€å­—æ®µæŸ¥è¯¢è¯·æ±‚...")
             fields_response = requests.get(fields_url, headers=headers, timeout=30)
             self.logger.info(f"   - å­—æ®µæŸ¥è¯¢å“åº”çŠ¶æ€: {fields_response.status_code}")
             
             field_types = {}
             available_fields = []
             
             if fields_response.status_code == 200:
                 fields_result = fields_response.json()
                 self.logger.info(f"   - å­—æ®µæŸ¥è¯¢å“åº”è§£æ: code={fields_result.get('code')}, msg={fields_result.get('msg', 'N/A')}")
                 
                 if fields_result.get('code') == 0:
                     fields_data = fields_result.get('data', {}).get('items', [])
                     field_types = {field.get('field_name'): field.get('type') for field in fields_data}
                     available_fields = [field.get('field_name') for field in fields_data]
                     self.logger.info(f"âœ… é£ä¹¦è¡¨æ ¼å­—æ®µä¿¡æ¯è·å–æˆåŠŸ:")
                     self.logger.info(f"   - å¯ç”¨å­—æ®µæ•°é‡: {len(available_fields)}")
                     self.logger.info(f"   - å¯ç”¨å­—æ®µåˆ—è¡¨: {available_fields}")
                     self.logger.info(f"   - å­—æ®µç±»å‹æ˜ å°„: {field_types}")
                 else:
                     self.logger.error(f"âŒ è·å–å­—æ®µä¿¡æ¯å¤±è´¥: {fields_result.get('msg')}")
             else:
                 self.logger.error(f"âŒ è·å–å­—æ®µä¿¡æ¯è¯·æ±‚å¤±è´¥: HTTP {fields_response.status_code}")
                 self.logger.error(f"   - å“åº”å†…å®¹: {fields_response.text[:200]}...")
             
             # å‡†å¤‡æ•°æ®è®°å½•
             self.logger.info(f"ğŸ”„ å¼€å§‹å‡†å¤‡æ•°æ®è®°å½•")
             self.logger.info(f"   - å¾…å¤„ç†æ•°æ®æ¡æ•°: {len(data)}")
             
             records = []
             skipped_fields = set()
             processed_fields = set()
             
             for idx, tweet in enumerate(data):
                 self.logger.info(f"   - å¤„ç†ç¬¬ {idx + 1}/{len(data)} æ¡æ•°æ®")
                 self.logger.debug(f"     - åŸå§‹æ•°æ®å­—æ®µ: {list(tweet.keys())}")
                 
                 # å¤„ç†æ—¶é—´å­—æ®µ - æ ¹æ®å­—æ®µç±»å‹å†³å®šæ ¼å¼
                 publish_time = tweet.get('å‘å¸ƒæ—¶é—´', '')
                 create_time = tweet.get('åˆ›å»ºæ—¶é—´', '')
                 
                 # è·å–æ—¶é—´å­—æ®µçš„ç±»å‹ï¼ˆ5=æ—¶é—´æˆ³ï¼Œ1=æ–‡æœ¬ï¼‰
                 publish_time_type = field_types.get('å‘å¸ƒæ—¶é—´', 5)  # é»˜è®¤ä¸ºæ—¶é—´æˆ³ç±»å‹
                 create_time_type = field_types.get('åˆ›å»ºæ—¶é—´', 1)   # é»˜è®¤ä¸ºæ–‡æœ¬ç±»å‹
                 
                 # å¤„ç†å‘å¸ƒæ—¶é—´ - è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³ï¼ˆé£ä¹¦è¦æ±‚ï¼‰
                 if isinstance(publish_time, str) and publish_time:
                     # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æå¹¶è½¬æ¢ä¸ºæ—¶é—´æˆ³
                     try:
                         from datetime import datetime
                         if 'T' in publish_time:  # ISOæ ¼å¼
                             dt = datetime.fromisoformat(publish_time.replace('Z', '+00:00'))
                             publish_time = int(dt.timestamp())
                         else:
                             # å°è¯•è§£æå¸¸è§æ ¼å¼
                             try:
                                 dt = datetime.strptime(publish_time, '%Y-%m-%d %H:%M:%S')
                                 publish_time = int(dt.timestamp())
                             except:
                                 # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                                 publish_time = int(datetime.now().timestamp())
                     except:
                         # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                         from datetime import datetime
                         publish_time = int(datetime.now().timestamp())
                 elif isinstance(publish_time, (int, float)) and publish_time > 0:
                     # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œç¡®ä¿æ˜¯ç§’çº§æ—¶é—´æˆ³
                     if publish_time > 10000000000:  # æ¯«ç§’æ—¶é—´æˆ³
                         publish_time = int(publish_time / 1000)
                     else:  # ç§’æ—¶é—´æˆ³
                         publish_time = int(publish_time)
                 else:
                     # é»˜è®¤ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
                     from datetime import datetime
                     publish_time = int(datetime.now().timestamp())
                 
                 # å¤„ç†åˆ›å»ºæ—¶é—´ - è½¬æ¢ä¸ºUnixæ—¶é—´æˆ³ï¼ˆé£ä¹¦è¦æ±‚ï¼‰
                 if isinstance(create_time, str) and create_time:
                     # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æå¹¶è½¬æ¢ä¸ºæ—¶é—´æˆ³
                     try:
                         from datetime import datetime
                         if 'T' in create_time:  # ISOæ ¼å¼
                             dt = datetime.fromisoformat(create_time.replace('Z', '+00:00'))
                             create_time = int(dt.timestamp())
                         else:
                             # å°è¯•è§£æå¸¸è§æ ¼å¼
                             try:
                                 dt = datetime.strptime(create_time, '%Y-%m-%d %H:%M:%S')
                                 create_time = int(dt.timestamp())
                             except:
                                 # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                                 create_time = int(datetime.now().timestamp())
                     except:
                         # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                         from datetime import datetime
                         create_time = int(datetime.now().timestamp())
                 elif isinstance(create_time, (int, float)) and create_time > 0:
                     # å¦‚æœå·²ç»æ˜¯æ•°å­—ï¼Œç¡®ä¿æ˜¯ç§’çº§æ—¶é—´æˆ³
                     if create_time > 10000000000:  # æ¯«ç§’æ—¶é—´æˆ³
                         create_time = int(create_time / 1000)
                     else:  # ç§’æ—¶é—´æˆ³
                         create_time = int(create_time)
                 else:
                     # é»˜è®¤ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
                     from datetime import datetime
                     create_time = int(datetime.now().timestamp())
                 
                 # å¤„ç†æ•°å€¼å­—æ®µ - ç¡®ä¿æ•°å€¼å­—æ®µä¸ºæœ‰æ•ˆæ•°å­—
                 def safe_int(value, default=0):
                     """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
                     try:
                         if value is None or value == '':
                             return default
                         return int(float(str(value)))
                     except (ValueError, TypeError):
                         return default
                 
                 # æ„å»ºè®°å½•æ•°æ®ï¼ŒåªåŒ…å«é£ä¹¦è¡¨æ ¼ä¸­å­˜åœ¨çš„å­—æ®µ
                 # ç›´æ¥ä½¿ç”¨é£ä¹¦è¡¨æ ¼ä¸­çš„å®é™…å­—æ®µåç§°è¿›è¡Œæ˜ å°„
                 
                 # æ ¹æ®é£ä¹¦è¡¨æ ¼çš„å®é™…å­—æ®µåç§°è¿›è¡Œæ˜ å°„
                 # åŸºäºç”¨æˆ·æä¾›çš„é£ä¹¦è¡¨æ ¼æˆªå›¾ï¼Œå­—æ®µåŒ…æ‹¬ï¼šæ¨æ–‡åŸæ–‡å†…å®¹ã€æ•°å­—å¼ã€è¯„è®ºã€è½¬å‘ã€ç‚¹èµã€åˆ›å»ºæ—¶é—´ç­‰
                 all_possible_fields = {
                     # æ¨æ–‡å†…å®¹å­—æ®µ - ç›´æ¥ä½¿ç”¨"æ¨æ–‡åŸæ–‡å†…å®¹"
                     'æ¨æ–‡åŸæ–‡å†…å®¹': str(tweet.get('æ¨æ–‡åŸæ–‡å†…å®¹', '') or tweet.get('æ¨æ–‡åŸ æ–‡å†…å®¹', '')),
                     
                     # ä½œè€…ä¿¡æ¯
                     'ä½œè€…ï¼ˆè´¦å·ï¼‰': str(tweet.get('ä½œè€…ï¼ˆè´¦å·ï¼‰', '')),
                     
                     # é“¾æ¥ä¿¡æ¯
                     'æ¨æ–‡é“¾æ¥': str(tweet.get('æ¨æ–‡é“¾æ¥', '')),
                     
                     # æ ‡ç­¾ä¿¡æ¯
                     'è¯é¢˜æ ‡ç­¾ï¼ˆHashtagï¼‰': str(tweet.get('è¯é¢˜æ ‡ç­¾ï¼ˆHashtagï¼‰', '')),
                     'ç±»å‹æ ‡ç­¾': str(tweet.get('ç±»å‹æ ‡ç­¾', '')),
                     
                     # æ•°å€¼å­—æ®µ - ç›´æ¥ä½¿ç”¨å­—æ®µåç§°
                     'è¯„è®º': safe_int(tweet.get('è¯„è®ºæ•°', 0) or tweet.get('è¯„è®º', 0)),
                     'è½¬å‘': safe_int(tweet.get('è½¬å‘æ•°', 0) or tweet.get('è½¬å‘', 0)),
                     'ç‚¹èµ': safe_int(tweet.get('ç‚¹èµæ•°', 0) or tweet.get('ç‚¹èµ', 0)),
                     
                     # æ—¶é—´å­—æ®µ - éƒ½ä½¿ç”¨Unixæ—¶é—´æˆ³æ ¼å¼
                     'åˆ›å»ºæ—¶é—´': create_time,  # Unixæ—¶é—´æˆ³æ ¼å¼
                     'å‘å¸ƒæ—¶é—´': publish_time  # Unixæ—¶é—´æˆ³æ ¼å¼
                 }
                 
                 # åªä¿ç•™é£ä¹¦è¡¨æ ¼ä¸­å®é™…å­˜åœ¨çš„å­—æ®µ
                 record_fields = {}
                 for field_name, field_value in all_possible_fields.items():
                     if field_name in available_fields:
                         record_fields[field_name] = field_value
                         processed_fields.add(field_name)
                         self.logger.debug(f"     - å­—æ®µ {field_name}: {str(field_value)[:50]}...")
                     else:
                         skipped_fields.add(field_name)
                         self.logger.debug(f"     - è·³è¿‡å­—æ®µ '{field_name}' (ä¸å­˜åœ¨äºé£ä¹¦è¡¨æ ¼)")
                 
                 self.logger.info(f"     - ç¬¬ {idx + 1} æ¡è®°å½•ä½¿ç”¨å­—æ®µæ•°: {len(record_fields)}")
                 self.logger.debug(f"     - ä½¿ç”¨å­—æ®µ: {list(record_fields.keys())}")
                 
                 if record_fields:
                     record = {'fields': record_fields}
                     records.append(record)
                 else:
                     self.logger.warning(f"âš ï¸ ç¬¬ {idx + 1} æ¡æ•°æ®æ²¡æœ‰åŒ¹é…çš„å­—æ®µï¼Œè·³è¿‡")
             
             self.logger.info(f"âœ… æ•°æ®è®°å½•å‡†å¤‡å®Œæˆ:")
             self.logger.info(f"   - åŸå§‹æ•°æ®æ¡æ•°: {len(data)}")
             self.logger.info(f"   - æœ‰æ•ˆè®°å½•æ•°: {len(records)}")
             self.logger.info(f"   - æˆåŠŸå¤„ç†ç‡: {len(records)/len(data)*100:.1f}%")
             self.logger.info(f"   - å¤„ç†çš„å­—æ®µ: {list(processed_fields)}")
             if skipped_fields:
                 self.logger.warning(f"âš ï¸ è·³è¿‡çš„å­—æ®µ (ä¸å­˜åœ¨äºé£ä¹¦è¡¨æ ¼): {list(skipped_fields)}")
             
             # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆè®°å½•
             if not records:
                 self.logger.warning(f"âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®è®°å½•å¯ä»¥åŒæ­¥")
                 return False
             
             # æ‰¹é‡åˆ›å»ºè®°å½•
             self.logger.info(f"ğŸ“¤ [CloudSync] å¼€å§‹æ‰¹é‡åˆ›å»ºé£ä¹¦è®°å½•")
             url = f"{self.feishu_config['base_url']}/bitable/v1/apps/{spreadsheet_token}/tables/{table_id}/records/batch_create"
             self.logger.info(f"   - åˆ›å»ºURL: {url}")
             
             payload = {
                 'records': records
             }
             self.logger.info(f"   - è®°å½•æ•°é‡: {len(records)}")
             self.logger.info(f"   - è½½è·å¤§å°: {len(str(payload))} å­—ç¬¦")
             self.logger.info(f"   - è½½è·ç¤ºä¾‹: {str(payload)[:200]}...")
             
             self.logger.info(f"ğŸŒ [CloudSync] å‘é€é£ä¹¦APIè¯·æ±‚...")
             response = requests.post(url, headers=headers, json=payload, timeout=60)
             self.logger.info(f"ğŸ“Š [CloudSync] é£ä¹¦APIå“åº”çŠ¶æ€ç : {response.status_code}")
             
             response.raise_for_status()
             
             result = response.json()
             self.logger.info(f"ğŸ“Š [CloudSync] é£ä¹¦APIå“åº”è§£æ: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
             
             if result.get('code') == 0:
                 created_records = result.get('data', {}).get('records', [])
                 self.logger.info(f"âœ… [CloudSync] æˆåŠŸåŒæ­¥åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼:")
                 self.logger.info(f"   - åŸå§‹æ•°æ®æ¡æ•°: {len(data)}")
                 self.logger.info(f"   - æœ‰æ•ˆè®°å½•æ•°: {len(records)}")
                 self.logger.info(f"   - åˆ›å»ºæˆåŠŸæ•°: {len(created_records)}")
                 return True
             else:
                 self.logger.error(f"âŒ [CloudSync] é£ä¹¦åŒæ­¥å¤±è´¥: {result.get('msg')}")
                 self.logger.error(f"   - é”™è¯¯è¯¦æƒ…: {result}")
                 return False
                 
        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ é£ä¹¦åŒæ­¥ç½‘ç»œè¯·æ±‚å¼‚å¸¸:")
            self.logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                self.logger.error(f"   - å“åº”çŠ¶æ€ç : {e.response.status_code}")
                self.logger.error(f"   - å“åº”å†…å®¹: {e.response.text[:500]}...")
            raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†é‡è¯•é€»è¾‘
        except Exception as e:
            self.logger.error(f"âŒ é£ä¹¦åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯:")
            self.logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            import traceback
            self.logger.error(f"   - å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†é‡è¯•é€»è¾‘
    
    def sync_to_feishu_sheet(self, data: List[Dict[str, Any]], 
                            spreadsheet_token: str, 
                            sheet_id: str = None) -> bool:
        """
        åŒæ­¥æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼
        
        Args:
            data: è¦åŒæ­¥çš„æ•°æ®
            spreadsheet_token: é£ä¹¦è¡¨æ ¼token
            sheet_id: å·¥ä½œè¡¨ID
            
        Returns:
            æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        self.logger.info(f"ğŸ“Š å¼€å§‹é£ä¹¦è¡¨æ ¼åŒæ­¥æµç¨‹")
        self.logger.info(f"   - è¡¨æ ¼Token: {spreadsheet_token[:10]}...")
        self.logger.info(f"   - å·¥ä½œè¡¨ID: {sheet_id}")
        self.logger.info(f"   - æ•°æ®æ¡æ•°: {len(data)}")
        
        self.logger.info(f"ğŸ”‘ è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ")
        access_token = self.get_feishu_access_token()
        if not access_token:
            self.logger.error(f"âŒ é£ä¹¦è®¿é—®ä»¤ç‰Œè·å–å¤±è´¥")
            return False
        self.logger.info(f"âœ… é£ä¹¦è®¿é—®ä»¤ç‰Œè·å–æˆåŠŸ")
            
        try:
            headers = {
                'Authorization': f'Bearer {access_token}',
                'Content-Type': 'application/json'
            }
            self.logger.info(f"âœ… è¯·æ±‚å¤´è®¾ç½®å®Œæˆ")
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šsheet_idï¼Œè·å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            if not sheet_id:
                self.logger.info(f"ğŸ” æœªæŒ‡å®šå·¥ä½œè¡¨IDï¼Œè·å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨")
                url = f"{self.feishu_config['base_url']}/sheets/v3/spreadsheets/{spreadsheet_token}/sheets/query"
                self.logger.info(f"   - æŸ¥è¯¢URL: {url}")
                
                response = requests.get(url, headers=headers)
                self.logger.info(f"   - å“åº”çŠ¶æ€ç : {response.status_code}")
                response.raise_for_status()
                
                result = response.json()
                self.logger.info(f"   - å“åº”ç»“æœ: code={result.get('code')}")
                
                if result.get('code') == 0 and result.get('data', {}).get('sheets'):
                    sheet_id = result['data']['sheets'][0]['sheet_id']
                    self.logger.info(f"âœ… è·å–åˆ°å·¥ä½œè¡¨ID: {sheet_id}")
                else:
                    self.logger.error(f"âŒ æ— æ³•è·å–é£ä¹¦å·¥ä½œè¡¨ä¿¡æ¯: {result.get('msg')}")
                    return False
            else:
                self.logger.info(f"â„¹ï¸ ä½¿ç”¨æŒ‡å®šçš„å·¥ä½œè¡¨ID: {sheet_id}")
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            self.logger.info(f"ğŸ§¹ æ¸…ç©ºç°æœ‰æ•°æ®")
            clear_url = f"{self.feishu_config['base_url']}/sheets/v2/spreadsheets/{spreadsheet_token}/values_batch_clear"
            clear_payload = {
                'ranges': [f'{sheet_id}!A:Z']
            }
            self.logger.info(f"   - æ¸…ç©ºURL: {clear_url}")
            self.logger.info(f"   - æ¸…ç©ºèŒƒå›´: {clear_payload['ranges']}")
            
            clear_response = requests.post(clear_url, headers=headers, json=clear_payload)
            self.logger.info(f"   - æ¸…ç©ºå“åº”çŠ¶æ€ç : {clear_response.status_code}")
            
            if not data:
                self.logger.warning(f"âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
                return True
            
            # å‡†å¤‡æ•°æ®
            self.logger.info(f"ğŸ”„ å¼€å§‹å‡†å¤‡è¡¨æ ¼æ•°æ®")
            values = [[
                'åºå·', 'ç”¨æˆ·å', 'æ¨æ–‡å†…å®¹', 'å‘å¸ƒæ—¶é—´', 'è¯„è®ºæ•°', 
                'è½¬å‘æ•°', 'ç‚¹èµæ•°', 'é“¾æ¥', 'æ ‡ç­¾', 'ç­›é€‰çŠ¶æ€'
            ]]
            self.logger.info(f"   - è¡¨å¤´è®¾ç½®å®Œæˆ: {values[0]}")
            
            for i, tweet in enumerate(data, 1):
                row = [
                    str(i),
                    tweet.get('username', ''),
                    tweet.get('content', ''),
                    tweet.get('timestamp', ''),
                    str(tweet.get('comments', 0)),
                    str(tweet.get('retweets', 0)),
                    str(tweet.get('likes', 0)),
                    tweet.get('link', ''),
                    ', '.join(tweet.get('tags', [])),
                    tweet.get('filter_status', '')
                ]
                values.append(row)
                if i <= 3:  # åªè®°å½•å‰3è¡Œçš„è¯¦ç»†ä¿¡æ¯
                    self.logger.debug(f"   - ç¬¬ {i} è¡Œæ•°æ®: {row[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ªå­—æ®µ
            
            self.logger.info(f"âœ… è¡¨æ ¼æ•°æ®å‡†å¤‡å®Œæˆ:")
            self.logger.info(f"   - æ€»è¡Œæ•°: {len(values)} (åŒ…å«è¡¨å¤´)")
            self.logger.info(f"   - æ•°æ®è¡Œæ•°: {len(values) - 1}")
            
            # æ‰¹é‡æ›´æ–°æ•°æ®
            self.logger.info(f"ğŸ“¤ å¼€å§‹æ‰¹é‡æ›´æ–°è¡¨æ ¼æ•°æ®")
            update_url = f"{self.feishu_config['base_url']}/sheets/v2/spreadsheets/{spreadsheet_token}/values_batch_update"
            update_payload = {
                'value_ranges': [{
                    'range': f'{sheet_id}!A1:J{len(values)}',
                    'values': values
                }]
            }
            
            self.logger.info(f"   - æ›´æ–°URL: {update_url}")
            self.logger.info(f"   - æ›´æ–°èŒƒå›´: {update_payload['value_ranges'][0]['range']}")
            self.logger.info(f"   - è½½è·å¤§å°: {len(values)} è¡Œæ•°æ®")
            
            self.logger.info(f"ğŸŒ å‘é€è¡¨æ ¼æ›´æ–°è¯·æ±‚...")
            response = requests.post(update_url, headers=headers, json=update_payload)
            self.logger.info(f"   - å“åº”çŠ¶æ€ç : {response.status_code}")
            response.raise_for_status()
            
            result = response.json()
            self.logger.info(f"   - å“åº”ç»“æœ: code={result.get('code')}, msg={result.get('msg', 'N/A')}")
            
            if result.get('code') == 0:
                self.logger.info(f"âœ… æˆåŠŸåŒæ­¥ {len(data)} æ¡æ•°æ®åˆ°é£ä¹¦è¡¨æ ¼")
                return True
            else:
                self.logger.error(f"âŒ é£ä¹¦è¡¨æ ¼åŒæ­¥å¤±è´¥: {result.get('msg')}")
                return False
                
        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ é£ä¹¦è¡¨æ ¼åŒæ­¥ç½‘ç»œè¯·æ±‚å¼‚å¸¸:")
            self.logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                self.logger.error(f"   - å“åº”çŠ¶æ€ç : {e.response.status_code}")
                self.logger.error(f"   - å“åº”å†…å®¹: {e.response.text[:500]}...")
            return False
        except Exception as e:
            self.logger.error(f"âŒ é£ä¹¦è¡¨æ ¼åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯:")
            self.logger.error(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            self.logger.error(f"   - å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            import traceback
            self.logger.error(f"   - å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return False
    
    async def sync_all_platforms(self, data: List[Dict[str, Any]], 
                                sync_config: Dict[str, Any]) -> Dict[str, bool]:
        """
        åŒæ­¥åˆ°æ‰€æœ‰é…ç½®çš„å¹³å°
        
        Args:
            data: è¦åŒæ­¥çš„æ•°æ®
            sync_config: åŒæ­¥é…ç½®
            
        Returns:
            å„å¹³å°åŒæ­¥ç»“æœ
        """
        results = {}
        
        # Google SheetsåŒæ­¥
        google_config = sync_config.get('google_sheets', {})
        if google_config.get('enabled', False):
            if self.setup_google_sheets(google_config.get('credentials_file')):
                results['google_sheets'] = self.sync_to_google_sheets(
                    data, 
                    google_config.get('spreadsheet_id'),
                    google_config.get('worksheet_name')
                )
            else:
                results['google_sheets'] = False
        
        # é£ä¹¦åŒæ­¥
        feishu_config = sync_config.get('feishu', {})
        if feishu_config.get('enabled', False):
            if self.setup_feishu(
                feishu_config.get('app_id'),
                feishu_config.get('app_secret')
            ):
                results['feishu'] = self.sync_to_feishu_sheet(
                    data,
                    feishu_config.get('spreadsheet_token'),
                    feishu_config.get('sheet_id')
                )
            else:
                results['feishu'] = False
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹é…ç½®
    sync_config = {
        'google_sheets': {
            'enabled': True,
            'credentials_file': 'path/to/google-credentials.json',
            'spreadsheet_id': 'your-google-spreadsheet-id',
            'worksheet_name': 'Twitteræ•°æ®'
        },
        'feishu': {
            'enabled': True,
            'app_id': 'your-feishu-app-id',
            'app_secret': 'your-feishu-app-secret',
            'spreadsheet_token': 'your-feishu-spreadsheet-token',
            'sheet_id': 'your-sheet-id'  # å¯é€‰
        }
    }
    
    # ç¤ºä¾‹æ•°æ®
    sample_data = [
        {
            'username': 'elonmusk',
            'content': 'Sample tweet content',
            'timestamp': '2024-01-01 12:00:00',
            'likes': 1000,
            'comments': 100,
            'retweets': 500,
            'link': 'https://twitter.com/elonmusk/status/123',
            'tags': ['AI', 'Technology'],
            'filter_status': 'passed'
        }
    ]
    
    # åˆ›å»ºåŒæ­¥ç®¡ç†å™¨å¹¶æ‰§è¡ŒåŒæ­¥
    sync_manager = CloudSyncManager()
    
    async def main():
        results = await sync_manager.sync_all_platforms(sample_data, sync_config)
        print(f"åŒæ­¥ç»“æœ: {results}")
    
    asyncio.run(main())