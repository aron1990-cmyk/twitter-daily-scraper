#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é£ä¹¦æ•°æ®éªŒè¯åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–°å¢çš„æ•°æ®éªŒè¯åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from web_app import app, FEISHU_CONFIG, ScrapingTask, TweetData, db
from feishu_data_validator import FeishuDataValidator
from datetime import datetime
import json

def test_feishu_validation():
    """æµ‹è¯•é£ä¹¦æ•°æ®éªŒè¯åŠŸèƒ½"""
    with app.app_context():
        print("ğŸ§ª æµ‹è¯•é£ä¹¦æ•°æ®éªŒè¯åŠŸèƒ½")
        print("=" * 60)
        
        # 1. æ£€æŸ¥é£ä¹¦é…ç½®
        print("\nğŸ”§ æ£€æŸ¥é£ä¹¦é…ç½®:")
        print(f"   - é£ä¹¦å¯ç”¨: {FEISHU_CONFIG.get('enabled', False)}")
        print(f"   - è‡ªåŠ¨åŒæ­¥: {FEISHU_CONFIG.get('auto_sync', False)}")
        print(f"   - App ID: {'å·²é…ç½®' if FEISHU_CONFIG.get('app_id') else 'æœªé…ç½®'}")
        print(f"   - App Secret: {'å·²é…ç½®' if FEISHU_CONFIG.get('app_secret') else 'æœªé…ç½®'}")
        print(f"   - è¡¨æ ¼Token: {'å·²é…ç½®' if FEISHU_CONFIG.get('spreadsheet_token') else 'æœªé…ç½®'}")
        print(f"   - è¡¨æ ¼ID: {'å·²é…ç½®' if FEISHU_CONFIG.get('table_id') else 'æœªé…ç½®'}")
        
        # æ£€æŸ¥é…ç½®å®Œæ•´æ€§
        required_fields = ['app_id', 'app_secret', 'spreadsheet_token', 'table_id']
        missing_fields = [field for field in required_fields if not FEISHU_CONFIG.get(field)]
        
        if missing_fields:
            print(f"   âŒ é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}")
            print("\nğŸ’¡ è¯·å…ˆå®Œæˆé£ä¹¦é…ç½®åå†æµ‹è¯•éªŒè¯åŠŸèƒ½")
            return False
        
        if not FEISHU_CONFIG.get('enabled'):
            print("   âŒ é£ä¹¦åŒæ­¥æœªå¯ç”¨")
            print("\nğŸ’¡ è¯·å…ˆå¯ç”¨é£ä¹¦åŒæ­¥åå†æµ‹è¯•éªŒè¯åŠŸèƒ½")
            return False
        
        print("   âœ… é£ä¹¦é…ç½®å®Œæ•´ä¸”å·²å¯ç”¨")
        
        # 2. æŸ¥æ‰¾æœ‰æ•°æ®çš„ä»»åŠ¡
        print("\nğŸ“‹ æŸ¥æ‰¾å¯ç”¨ä»»åŠ¡:")
        tasks_with_data = db.session.query(ScrapingTask).join(TweetData).filter(
            TweetData.task_id == ScrapingTask.id
        ).distinct().all()
        
        if not tasks_with_data:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°åŒ…å«æ¨æ–‡æ•°æ®çš„ä»»åŠ¡")
            print("\nğŸ’¡ è¯·å…ˆè¿è¡ŒæŠ“å–ä»»åŠ¡è·å–ä¸€äº›æ¨æ–‡æ•°æ®")
            return False
        
        print(f"   âœ… æ‰¾åˆ° {len(tasks_with_data)} ä¸ªåŒ…å«æ•°æ®çš„ä»»åŠ¡")
        
        # é€‰æ‹©æœ€æ–°çš„ä»»åŠ¡è¿›è¡Œæµ‹è¯•
        test_task = max(tasks_with_data, key=lambda t: t.id)
        tweet_count = TweetData.query.filter_by(task_id=test_task.id).count()
        synced_count = TweetData.query.filter_by(task_id=test_task.id, synced_to_feishu=True).count()
        
        print(f"   - é€‰æ‹©ä»»åŠ¡: {test_task.name} (ID: {test_task.id})")
        print(f"   - æ¨æ–‡æ€»æ•°: {tweet_count}")
        print(f"   - å·²åŒæ­¥æ•°: {synced_count}")
        print(f"   - åŒæ­¥ç‡: {synced_count/tweet_count*100:.1f}%" if tweet_count > 0 else "   - åŒæ­¥ç‡: 0%")
        
        if synced_count == 0:
            print("   âš ï¸ è¯¥ä»»åŠ¡å°šæœªåŒæ­¥ä»»ä½•æ•°æ®åˆ°é£ä¹¦")
            print("\nğŸ’¡ å»ºè®®å…ˆåŒæ­¥ä¸€äº›æ•°æ®åˆ°é£ä¹¦åå†æµ‹è¯•éªŒè¯åŠŸèƒ½")
            # æ³¨æ„ï¼šå³ä½¿æ²¡æœ‰åŒæ­¥æ•°æ®ï¼ŒéªŒè¯å™¨åŠŸèƒ½æœ¬èº«ä»å¯èƒ½æ­£å¸¸å·¥ä½œ
            # è¿™é‡Œä¸ç›´æ¥è¿”å›Falseï¼Œè€Œæ˜¯ç»§ç»­æµ‹è¯•éªŒè¯å™¨åŠŸèƒ½
        
        # 3. æµ‹è¯•æ•°æ®éªŒè¯å™¨
        print("\nğŸ” æµ‹è¯•æ•°æ®éªŒè¯å™¨:")
        try:
            validator = FeishuDataValidator()
            print("   âœ… éªŒè¯å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # æ‰§è¡ŒéªŒè¯
            print(f"\nğŸš€ å¼€å§‹éªŒè¯ä»»åŠ¡ {test_task.id} çš„æ•°æ®...")
            validation_result = validator.validate_sync_data(task_id=test_task.id)
            
            if validation_result.get('success'):
                print("   âœ… éªŒè¯æ‰§è¡ŒæˆåŠŸ")
                
                # æ˜¾ç¤ºéªŒè¯ç»“æœ
                comparison = validation_result.get('comparison_result', {})
                summary = comparison.get('summary', {})
                
                print("\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:")
                print(f"   - æœ¬åœ°è®°å½•æ•°: {summary.get('total_local', 0)}")
                print(f"   - é£ä¹¦è®°å½•æ•°: {summary.get('total_feishu', 0)}")
                print(f"   - åŒ¹é…è®°å½•æ•°: {summary.get('matched_count', 0)}")
                print(f"   - åŒæ­¥å‡†ç¡®ç‡: {summary.get('sync_accuracy', 0):.2f}%")
                
                print("\nğŸ“‹ è¯¦ç»†ç»Ÿè®¡:")
                print(f"   - å®Œå…¨åŒ¹é…: {len(comparison.get('matched_records', []))} æ¡")
                print(f"   - é£ä¹¦ç¼ºå¤±: {len(comparison.get('missing_in_feishu', []))} æ¡")
                print(f"   - é£ä¹¦å¤šä½™: {len(comparison.get('extra_in_feishu', []))} æ¡")
                print(f"   - å­—æ®µä¸åŒ¹é…: {len(comparison.get('field_mismatches', []))} æ¡")
                
                # è´¨é‡è¯„ä¼°
                sync_accuracy = summary.get('sync_accuracy', 0)
                if sync_accuracy >= 95:
                    print("\nğŸ‰ æ•°æ®åŒæ­¥è´¨é‡: ä¼˜ç§€")
                elif sync_accuracy >= 85:
                    print("\nâš ï¸ æ•°æ®åŒæ­¥è´¨é‡: è‰¯å¥½")
                else:
                    print(f"\nâŒ æ•°æ®åŒæ­¥è´¨é‡: éœ€è¦æ”¹è¿› (å‡†ç¡®ç‡ {sync_accuracy:.2f}%)")
                
                # æ˜¾ç¤ºé—®é¢˜æ ·ä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
                missing_in_feishu = comparison.get('missing_in_feishu', [])
                if missing_in_feishu:
                    print(f"\nâŒ é£ä¹¦ä¸­ç¼ºå¤±çš„è®°å½• ({len(missing_in_feishu)} æ¡):")
                    for i, missing in enumerate(missing_in_feishu[:3]):
                        content = missing.get('content', missing.get('æ¨æ–‡åŸæ–‡å†…å®¹', ''))[:50]
                        print(f"   {i+1}. {content}...")
                    if len(missing_in_feishu) > 3:
                        print(f"   ... è¿˜æœ‰ {len(missing_in_feishu) - 3} æ¡")
                
                extra_in_feishu = comparison.get('extra_in_feishu', [])
                if extra_in_feishu:
                    print(f"\nâš ï¸ é£ä¹¦ä¸­å¤šä½™çš„è®°å½• ({len(extra_in_feishu)} æ¡):")
                    for i, extra in enumerate(extra_in_feishu[:3]):
                        content = extra.get('æ¨æ–‡åŸæ–‡å†…å®¹', '')[:50]
                        print(f"   {i+1}. {content}...")
                    if len(extra_in_feishu) > 3:
                        print(f"   ... è¿˜æœ‰ {len(extra_in_feishu) - 3} æ¡")
                
                field_mismatches = comparison.get('field_mismatches', [])
                if field_mismatches:
                    print(f"\nğŸ”„ å­—æ®µå€¼ä¸åŒ¹é…çš„è®°å½• ({len(field_mismatches)} æ¡):")
                    for i, mismatch in enumerate(field_mismatches[:3]):
                        content = mismatch.get('content', 'No content available')
                        mismatched_fields = mismatch.get('mismatched_fields', [])
                        print(f"   {i+1}. {content}")
                        for field_info in mismatched_fields[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªä¸åŒ¹é…å­—æ®µ
                            field_name = field_info.get('field', '')
                            local_value = field_info.get('local_value', '')
                            feishu_value = field_info.get('feishu_value', '')
                            print(f"      - {field_name}: æœ¬åœ°='{local_value}' vs é£ä¹¦='{feishu_value}'")
                
                print(f"\nâœ… [FEISHU_VALIDATE] éªŒè¯å®Œæˆ")
                print(f"ğŸ“Š [FEISHU_VALIDATE] åŒæ­¥å‡†ç¡®ç‡: {sync_accuracy:.2f}%")
                
                # éªŒè¯å™¨åŠŸèƒ½æµ‹è¯•æˆåŠŸçš„æ ‡å‡†æ˜¯èƒ½å¤Ÿæ­£å¸¸æ‰§è¡ŒéªŒè¯ï¼Œè€Œä¸æ˜¯æ•°æ®è´¨é‡
                print("\nğŸ‰ éªŒè¯å™¨åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼éªŒè¯å™¨èƒ½å¤Ÿæ­£å¸¸æ‰§è¡Œå¹¶è¿”å›ç»“æœ")
                return True
                
            else:
                error_msg = validation_result.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"   âŒ éªŒè¯æ‰§è¡Œå¤±è´¥: {error_msg}")
                return False
                
        except Exception as e:
            print(f"   âŒ éªŒè¯å™¨æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            print(f"   ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return False

def test_api_endpoint():
    """æµ‹è¯•APIç«¯ç‚¹"""
    print("\nğŸŒ æµ‹è¯•APIç«¯ç‚¹åŠŸèƒ½")
    print("=" * 40)
    
    with app.app_context():
        # æŸ¥æ‰¾æœ‰æ•°æ®çš„ä»»åŠ¡
        tasks_with_data = db.session.query(ScrapingTask).join(TweetData).filter(
            TweetData.task_id == ScrapingTask.id,
            TweetData.synced_to_feishu == True
        ).distinct().all()
        
        if not tasks_with_data:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°å·²åŒæ­¥çš„ä»»åŠ¡æ•°æ®")
            return False
        
        test_task = tasks_with_data[0]
        print(f"   - æµ‹è¯•ä»»åŠ¡: {test_task.name} (ID: {test_task.id})")
        
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        with app.test_client() as client:
            print(f"   - è°ƒç”¨API: POST /api/data/validate_feishu/{test_task.id}")
            
            response = client.post(f'/api/data/validate_feishu/{test_task.id}')
            
            print(f"   - å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                # å…ˆè·å–åŸå§‹å“åº”æ–‡æœ¬
                response_text = response.get_data(as_text=True)
                print(f"   - å“åº”å†…å®¹ç±»å‹: {response.content_type}")
                
                try:
                    # å°è¯•è§£æJSON
                    data = json.loads(response_text)
                    
                    if data.get('success'):
                        report = data.get('validation_report', {})
                        summary = report.get('summary', {})
                        print(f"   âœ… APIè°ƒç”¨æˆåŠŸï¼Œå‡†ç¡®ç‡: {summary.get('sync_accuracy', 0):.2f}%")
                        print(f"   - åŒ¹é…è®°å½•: {summary.get('matched_count', 0)}")
                        print(f"   - æœ¬åœ°è®°å½•: {summary.get('total_local', 0)}")
                        print(f"   - é£ä¹¦è®°å½•: {summary.get('total_feishu', 0)}")
                        return True
                    else:
                        print(f"   âŒ APIè¿”å›å¤±è´¥: {data.get('error')}")
                        return False
                except json.JSONDecodeError as je:
                    print(f"   âŒ JSONè§£æå¤±è´¥: {je}")
                    print(f"   - å“åº”å†…å®¹: {response_text[:500]}...")  # åªæ˜¾ç¤ºå‰500å­—ç¬¦
                    return False
            else:
                print(f"   âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                response_text = response.get_data(as_text=True)
                print(f"   - å“åº”å†…å®¹: {response_text[:500]}...")  # åªæ˜¾ç¤ºå‰500å­—ç¬¦
                return False

if __name__ == '__main__':
    print("ğŸ§ª é£ä¹¦æ•°æ®éªŒè¯åŠŸèƒ½å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•éªŒè¯å™¨åŠŸèƒ½
    validator_success = test_feishu_validation()
    
    # æµ‹è¯•APIç«¯ç‚¹
    api_success = test_api_endpoint()
    
    print("\nğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 40)
    print(f"   - éªŒè¯å™¨åŠŸèƒ½: {'âœ… é€šè¿‡' if validator_success else 'âŒ å¤±è´¥'}")
    print(f"   - APIç«¯ç‚¹åŠŸèƒ½: {'âœ… é€šè¿‡' if api_success else 'âŒ å¤±è´¥'}")
    
    if validator_success and api_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é£ä¹¦æ•°æ®éªŒè¯åŠŸèƒ½å·²å°±ç»ª")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   1. åœ¨æ•°æ®æŸ¥çœ‹é¡µé¢é€‰æ‹©ä»»åŠ¡")
        print("   2. ç‚¹å‡»'éªŒè¯æ•°æ®'æŒ‰é’®")
        print("   3. æŸ¥çœ‹éªŒè¯ç»“æœå’Œå‡†ç¡®ç‡")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®")