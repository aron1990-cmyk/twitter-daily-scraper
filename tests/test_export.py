import pytest
import json
import sqlite3
import pandas as pd
from pathlib import Path
import tempfile
import os
import sys
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from excel_writer import ExcelWriter
from storage_manager import StorageManager
from models import Tweet

class TestDataExport:
    """æ•°æ®ä¿å­˜æ¨¡å—æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def sample_tweets_data(self):
        """åŠ è½½ç¤ºä¾‹æ¨æ–‡æ•°æ®"""
        fixtures_path = Path(__file__).parent / "fixtures" / "sample_tweets.json"
        with open(fixtures_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    @pytest.fixture
    def sample_tweets_objects(self, sample_tweets_data):
        """è½¬æ¢ä¸ºTweetå¯¹è±¡åˆ—è¡¨"""
        tweets = []
        for data in sample_tweets_data:
            tweet = Tweet(
                id=data['id'],
                username=data['username'],
                content=data['content'],
                timestamp=data['timestamp'],
                url=data['url'],
                likes=data['likes'],
                retweets=data['retweets'],
                replies=data['replies']
            )
            tweets.append(tweet)
        return tweets
    
    @pytest.fixture
    def temp_dir(self):
        """åˆ›å»ºä¸´æ—¶ç›®å½•"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield Path(temp_dir)
    
    def test_excel_export_basic(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•åŸºç¡€Excelå¯¼å‡ºåŠŸèƒ½
        
        éªŒè¯èƒ½å¤Ÿæ­£ç¡®å¯¼å‡ºæ¨æ–‡æ•°æ®åˆ°Excelæ–‡ä»¶
        """
        excel_writer = ExcelWriter()
        output_file = temp_dir / "test_tweets.xlsx"
        
        # æ‰§è¡Œå¯¼å‡º
        excel_writer.write_tweets_to_excel(sample_tweets_data, str(output_file))
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert output_file.exists()
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        df = pd.read_excel(output_file)
        assert len(df) == len(sample_tweets_data)
        
        # éªŒè¯å¿…éœ€å­—æ®µå­˜åœ¨
        required_columns = ['username', 'content', 'timestamp', 'url', 'likes', 'retweets', 'replies']
        for col in required_columns:
            assert col in df.columns
    
    def test_excel_export_custom_fields(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•è‡ªå®šä¹‰å­—æ®µExcelå¯¼å‡º
        
        éªŒè¯è‡ªå®šä¹‰å­—æ®µæ¨¡æ¿èƒ½å¤Ÿæ­£ç¡®åº”ç”¨åˆ°Excelå¯¼å‡º
        """
        excel_writer = ExcelWriter()
        output_file = temp_dir / "test_custom_tweets.xlsx"
        
        # å®šä¹‰è‡ªå®šä¹‰å­—æ®µ
        custom_fields = ['username', 'content', 'likes', 'url']
        
        # æ‰§è¡Œå¯¼å‡º
        excel_writer.write_tweets_to_excel(
            sample_tweets_data, 
            str(output_file),
            custom_fields=custom_fields
        )
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert output_file.exists()
        
        # éªŒè¯åªåŒ…å«æŒ‡å®šå­—æ®µ
        df = pd.read_excel(output_file)
        assert list(df.columns) == custom_fields
        assert len(df) == len(sample_tweets_data)
    
    def test_json_export_basic(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•åŸºç¡€JSONå¯¼å‡ºåŠŸèƒ½
        
        éªŒè¯èƒ½å¤Ÿæ­£ç¡®å¯¼å‡ºæ¨æ–‡æ•°æ®åˆ°JSONæ–‡ä»¶
        """
        output_file = temp_dir / "test_tweets.json"
        
        # æ‰§è¡Œå¯¼å‡º
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(sample_tweets_data, f, ensure_ascii=False, indent=2)
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert output_file.exists()
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        with open(output_file, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        
        assert len(loaded_data) == len(sample_tweets_data)
        assert loaded_data == sample_tweets_data
    
    def test_json_export_structure_validation(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•JSONå¯¼å‡ºç»“æ„éªŒè¯
        
        éªŒè¯å¯¼å‡ºçš„JSONæ–‡ä»¶ç»“æ„å®Œæ•´æ€§
        """
        output_file = temp_dir / "test_structure_tweets.json"
        
        # æ‰§è¡Œå¯¼å‡º
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(sample_tweets_data, f, ensure_ascii=False, indent=2)
        
        # éªŒè¯JSONç»“æ„
        with open(output_file, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        
        required_fields = ['id', 'username', 'content', 'timestamp', 'url']
        for tweet in loaded_data:
            for field in required_fields:
                assert field in tweet, f"Missing field {field} in exported JSON"
    
    def test_sqlite_export_basic(self, sample_tweets_objects, temp_dir):
        """æµ‹è¯•åŸºç¡€SQLiteå¯¼å‡ºåŠŸèƒ½
        
        éªŒè¯èƒ½å¤Ÿæ­£ç¡®å¯¼å‡ºæ¨æ–‡æ•°æ®åˆ°SQLiteæ•°æ®åº“
        """
        db_file = temp_dir / "test_tweets.db"
        storage_manager = StorageManager(str(db_file))
        
        # æ‰§è¡Œå¯¼å‡º
        for tweet in sample_tweets_objects:
            storage_manager.save_tweet(tweet)
        
        # éªŒè¯æ•°æ®åº“æ–‡ä»¶å­˜åœ¨
        assert db_file.exists()
        
        # éªŒè¯æ•°æ®åº“å†…å®¹
        conn = sqlite3.connect(str(db_file))
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM tweets")
        count = cursor.fetchone()[0]
        assert count == len(sample_tweets_objects)
        
        # éªŒè¯è¡¨ç»“æ„
        cursor.execute("PRAGMA table_info(tweets)")
        columns = [row[1] for row in cursor.fetchall()]
        required_columns = ['id', 'username', 'content', 'timestamp', 'url']
        for col in required_columns:
            assert col in columns
        
        conn.close()
    
    def test_sqlite_export_data_integrity(self, sample_tweets_objects, temp_dir):
        """æµ‹è¯•SQLiteå¯¼å‡ºæ•°æ®å®Œæ•´æ€§
        
        éªŒè¯å¯¼å‡ºåˆ°SQLiteçš„æ•°æ®å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
        """
        db_file = temp_dir / "test_integrity_tweets.db"
        storage_manager = StorageManager(str(db_file))
        
        # æ‰§è¡Œå¯¼å‡º
        for tweet in sample_tweets_objects:
            storage_manager.save_tweet(tweet)
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        conn = sqlite3.connect(str(db_file))
        cursor = conn.cursor()
        
        cursor.execute("SELECT * FROM tweets ORDER BY id")
        rows = cursor.fetchall()
        
        assert len(rows) == len(sample_tweets_objects)
        
        # éªŒè¯å…·ä½“æ•°æ®
        for i, row in enumerate(rows):
            original_tweet = sample_tweets_objects[i]
            assert str(row[0]) == original_tweet.id  # id
            assert row[1] == original_tweet.username  # username
            assert row[2] == original_tweet.content   # content
        
        conn.close()
    
    @pytest.mark.parametrize("export_format,file_extension", [
        ("excel", ".xlsx"),
        ("json", ".json"),
        ("sqlite", ".db")
    ])
    def test_multiple_export_formats(self, sample_tweets_data, temp_dir, export_format, file_extension):
        """æµ‹è¯•å¤šç§å¯¼å‡ºæ ¼å¼æ”¯æŒ
        
        éªŒè¯ç³»ç»Ÿæ”¯æŒExcelã€JSONã€SQLiteç­‰å¤šç§å¯¼å‡ºæ ¼å¼
        """
        output_file = temp_dir / f"test_tweets{file_extension}"
        
        if export_format == "excel":
            excel_writer = ExcelWriter()
            excel_writer.write_tweets_to_excel(sample_tweets_data, str(output_file))
        elif export_format == "json":
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(sample_tweets_data, f, ensure_ascii=False, indent=2)
        elif export_format == "sqlite":
            # åˆ›å»ºç®€å•çš„SQLiteæ•°æ®åº“
            conn = sqlite3.connect(str(output_file))
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE tweets (
                    id TEXT PRIMARY KEY,
                    username TEXT,
                    content TEXT,
                    timestamp TEXT,
                    url TEXT,
                    likes INTEGER,
                    retweets INTEGER,
                    replies INTEGER
                )
            ''')
            
            for tweet in sample_tweets_data:
                cursor.execute('''
                    INSERT INTO tweets VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    tweet['id'], tweet['username'], tweet['content'],
                    tweet['timestamp'], tweet['url'], tweet['likes'],
                    tweet['retweets'], tweet['replies']
                ))
            
            conn.commit()
            conn.close()
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert output_file.exists()
        assert output_file.stat().st_size > 0
    
    def test_excel_export_large_dataset(self, temp_dir):
        """æµ‹è¯•å¤§æ•°æ®é›†Excelå¯¼å‡º
        
        éªŒè¯Excelå¯¼å‡ºèƒ½å¤Ÿå¤„ç†å¤§é‡æ¨æ–‡æ•°æ®
        """
        # ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
        large_dataset = []
        for i in range(1000):
            tweet = {
                'id': str(i),
                'username': f'user_{i % 10}',
                'content': f'This is test tweet number {i}',
                'timestamp': '2024-01-15 10:00:00',
                'url': f'https://twitter.com/user_{i % 10}/status/{i}',
                'likes': i * 10,
                'retweets': i * 2,
                'replies': i
            }
            large_dataset.append(tweet)
        
        excel_writer = ExcelWriter()
        output_file = temp_dir / "large_dataset.xlsx"
        
        # æ‰§è¡Œå¯¼å‡º
        excel_writer.write_tweets_to_excel(large_dataset, str(output_file))
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨ä¸”å¤§å°åˆç†
        assert output_file.exists()
        assert output_file.stat().st_size > 10000  # è‡³å°‘10KB
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        df = pd.read_excel(output_file)
        assert len(df) == 1000
    
    def test_export_with_special_characters(self, temp_dir):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ•°æ®å¯¼å‡º
        
        éªŒè¯å¯¼å‡ºåŠŸèƒ½èƒ½å¤Ÿæ­£ç¡®å¤„ç†ç‰¹æ®Šå­—ç¬¦å’ŒUnicode
        """
        special_tweets = [
            {
                'id': '1',
                'username': 'test_user',
                'content': 'Tweet with emoji ğŸ˜€ğŸš€ and special chars: @#$%^&*()',
                'timestamp': '2024-01-15 10:00:00',
                'url': 'https://twitter.com/test_user/status/1',
                'likes': 100,
                'retweets': 20,
                'replies': 5
            },
            {
                'id': '2',
                'username': 'æµ‹è¯•ç”¨æˆ·',
                'content': 'åŒ…å«ä¸­æ–‡çš„æ¨æ–‡å†…å®¹ï¼Œæµ‹è¯•Unicodeæ”¯æŒ',
                'timestamp': '2024-01-15 11:00:00',
                'url': 'https://twitter.com/æµ‹è¯•ç”¨æˆ·/status/2',
                'likes': 50,
                'retweets': 10,
                'replies': 2
            }
        ]
        
        # æµ‹è¯•Excelå¯¼å‡º
        excel_writer = ExcelWriter()
        excel_file = temp_dir / "special_chars.xlsx"
        excel_writer.write_tweets_to_excel(special_tweets, str(excel_file))
        
        assert excel_file.exists()
        df = pd.read_excel(excel_file)
        assert len(df) == 2
        assert 'ğŸ˜€ğŸš€' in df.iloc[0]['content']
        assert 'ä¸­æ–‡' in df.iloc[1]['content']
        
        # æµ‹è¯•JSONå¯¼å‡º
        json_file = temp_dir / "special_chars.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(special_tweets, f, ensure_ascii=False, indent=2)
        
        assert json_file.exists()
        with open(json_file, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        assert len(loaded_data) == 2
        assert 'ğŸ˜€ğŸš€' in loaded_data[0]['content']
    
    def test_export_empty_dataset(self, temp_dir):
        """æµ‹è¯•ç©ºæ•°æ®é›†å¯¼å‡º
        
        éªŒè¯å½“æ²¡æœ‰æ¨æ–‡æ•°æ®æ—¶çš„å¯¼å‡ºå¤„ç†
        """
        empty_data = []
        
        # æµ‹è¯•Excelå¯¼å‡º
        excel_writer = ExcelWriter()
        excel_file = temp_dir / "empty.xlsx"
        excel_writer.write_tweets_to_excel(empty_data, str(excel_file))
        
        assert excel_file.exists()
        df = pd.read_excel(excel_file)
        assert len(df) == 0
        
        # æµ‹è¯•JSONå¯¼å‡º
        json_file = temp_dir / "empty.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(empty_data, f)
        
        assert json_file.exists()
        with open(json_file, 'r', encoding='utf-8') as f:
            loaded_data = json.load(f)
        assert len(loaded_data) == 0
    
    def test_export_file_permissions(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•å¯¼å‡ºæ–‡ä»¶æƒé™å¤„ç†
        
        éªŒè¯åœ¨æ–‡ä»¶æƒé™å—é™æ—¶çš„é”™è¯¯å¤„ç†
        """
        excel_writer = ExcelWriter()
        
        # å°è¯•å†™å…¥åˆ°ä¸å­˜åœ¨çš„ç›®å½•
        invalid_path = temp_dir / "nonexistent" / "test.xlsx"
        
        with pytest.raises(Exception):
            excel_writer.write_tweets_to_excel(sample_tweets_data, str(invalid_path))
    
    def test_custom_field_template_validation(self, sample_tweets_data, temp_dir):
        """æµ‹è¯•è‡ªå®šä¹‰å­—æ®µæ¨¡æ¿éªŒè¯
        
        éªŒè¯è‡ªå®šä¹‰å­—æ®µæ¨¡æ¿çš„æœ‰æ•ˆæ€§æ£€æŸ¥
        """
        excel_writer = ExcelWriter()
        output_file = temp_dir / "custom_template.xlsx"
        
        # æµ‹è¯•æœ‰æ•ˆçš„è‡ªå®šä¹‰å­—æ®µ
        valid_fields = ['username', 'content', 'likes']
        excel_writer.write_tweets_to_excel(
            sample_tweets_data, 
            str(output_file),
            custom_fields=valid_fields
        )
        
        df = pd.read_excel(output_file)
        assert list(df.columns) == valid_fields
        
        # æµ‹è¯•åŒ…å«æ— æ•ˆå­—æ®µçš„æ¨¡æ¿
        invalid_fields = ['username', 'nonexistent_field', 'content']
        output_file2 = temp_dir / "invalid_template.xlsx"
        
        # åº”è¯¥å¿½ç•¥æ— æ•ˆå­—æ®µæˆ–æŠ›å‡ºè­¦å‘Š
        excel_writer.write_tweets_to_excel(
            sample_tweets_data, 
            str(output_file2),
            custom_fields=invalid_fields
        )
        
        df2 = pd.read_excel(output_file2)
        # éªŒè¯åªåŒ…å«æœ‰æ•ˆå­—æ®µ
        valid_columns = [col for col in invalid_fields if col in sample_tweets_data[0].keys()]
        assert all(col in df2.columns for col in valid_columns)
    
    @pytest.mark.parametrize("batch_size", [10, 50, 100])
    def test_batch_export_performance(self, temp_dir, batch_size):
        """æµ‹è¯•æ‰¹é‡å¯¼å‡ºæ€§èƒ½
        
        éªŒè¯ä¸åŒæ‰¹é‡å¤§å°çš„å¯¼å‡ºæ€§èƒ½
        """
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = []
        for i in range(batch_size):
            tweet = {
                'id': str(i),
                'username': f'user_{i}',
                'content': f'Batch test tweet {i}',
                'timestamp': '2024-01-15 10:00:00',
                'url': f'https://twitter.com/user_{i}/status/{i}',
                'likes': i,
                'retweets': i // 2,
                'replies': i // 5
            }
            test_data.append(tweet)
        
        excel_writer = ExcelWriter()
        output_file = temp_dir / f"batch_{batch_size}.xlsx"
        
        # æ‰§è¡Œæ‰¹é‡å¯¼å‡º
        excel_writer.write_tweets_to_excel(test_data, str(output_file))
        
        # éªŒè¯ç»“æœ
        assert output_file.exists()
        df = pd.read_excel(output_file)
        assert len(df) == batch_size

if __name__ == "__main__":
    pytest.main(["-v", __file__])