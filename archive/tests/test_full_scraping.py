#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®Œæ•´çš„æŠ“å–æµç¨‹
"""

import asyncio
import json
from refactored_task_manager import RefactoredTaskManager

async def test_full_scraping():
    """æµ‹è¯•å®Œæ•´æŠ“å–æµç¨‹"""
    try:
        print("ğŸ”§ æ‰§è¡ŒæŠ“å–ä»»åŠ¡...")
        # ç›´æ¥è°ƒç”¨æŠ“å–å¼•æ“
        from twitter_scraping_engine import TwitterScrapingEngine
        from models import ScrapingConfig
        
        config = ScrapingConfig(
            target_accounts=['elonmusk'],
            target_keywords=[],
            max_tweets_per_target=3,
            max_total_tweets=3,
            min_likes=0,
            min_retweets=0,
            min_comments=0
        )
        
        engine = TwitterScrapingEngine()
        result = await engine.batch_scrape_first_time(config.target_accounts)
        
        print(f"\nâœ… æŠ“å–ç»“æœ: {result}")
        
        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„æœ€æ–°æ•°æ®
        print("\nğŸ”§ æ£€æŸ¥æ•°æ®åº“ä¸­çš„æœ€æ–°æ¨æ–‡...")
        import sqlite3
        
        # ç›´æ¥ä½¿ç”¨sqlite3æŸ¥è¯¢æ•°æ®åº“
        conn = sqlite3.connect('twitter_scraper.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„3æ¡æ¨æ–‡
        cursor.execute("""
            SELECT username, content, likes, comments, retweets, publish_time, created_at
            FROM tweets 
            ORDER BY created_at DESC 
            LIMIT 3
        """)
        latest_tweets = cursor.fetchall()
        
        print(f"\nğŸ“Š æ•°æ®åº“ä¸­æœ€æ–°çš„ {len(latest_tweets)} æ¡æ¨æ–‡:")
        for i, tweet in enumerate(latest_tweets, 1):
            username, content, likes, comments, retweets, publish_time, created_at = tweet
            print(f"\næ¨æ–‡ {i}:")
            print(f"  ç”¨æˆ·å: {username}")
            print(f"  å†…å®¹: {content[:100]}...")
            print(f"  ç‚¹èµæ•°: {likes}")
            print(f"  è¯„è®ºæ•°: {comments}")
            print(f"  è½¬å‘æ•°: {retweets}")
            print(f"  å‘å¸ƒæ—¶é—´: {publish_time}")
        
        conn.close()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»Ÿè®¡æ•°æ®
        has_stats = any(tweet[2] > 0 or tweet[3] > 0 or tweet[4] > 0 for tweet in latest_tweets)
        
        if has_stats:
            print("\nğŸ‰ ç»Ÿè®¡æ•°æ®æå–å’Œå­˜å‚¨æˆåŠŸï¼")
        else:
            print("\nâš ï¸ ç»Ÿè®¡æ•°æ®ä»ä¸ºé›¶ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    asyncio.run(test_full_scraping())