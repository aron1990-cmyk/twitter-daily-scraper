#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤åçš„é£ä¹¦åŒæ­¥æ—¶é—´é—®é¢˜
éªŒè¯å‘å¸ƒæ—¶é—´æ­£ç¡®è½¬æ¢å’Œåˆ›å»ºæ—¶é—´å­—æ®µç§»é™¤
"""

import json
from datetime import datetime
from web_app import app, db, TweetData, FEISHU_CONFIG, classify_content_type
from dateutil import parser

def test_time_conversion():
    """æµ‹è¯•æ—¶é—´è½¬æ¢é€»è¾‘"""
    print("ğŸ• æµ‹è¯•æ—¶é—´è½¬æ¢é€»è¾‘")
    print("=" * 50)
    
    with app.app_context():
        # è·å–å‡ æ¡æ¨æ–‡æ•°æ®è¿›è¡Œæµ‹è¯•
        tweets = TweetData.query.limit(5).all()
        
        if not tweets:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨æ–‡æ•°æ®")
            return
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(tweets)} æ¡æ¨æ–‡ç”¨äºæµ‹è¯•")
        
        for i, tweet in enumerate(tweets, 1):
            print(f"\nğŸ” æµ‹è¯•æ¨æ–‡ {i}:")
            print(f"   - ID: {tweet.id}")
            print(f"   - ç”¨æˆ·: {tweet.username}")
            print(f"   - åŸå§‹å‘å¸ƒæ—¶é—´: {repr(tweet.publish_time)}")
            print(f"   - æŠ“å–æ—¶é—´: {tweet.scraped_at}")
            
            # æ¨¡æ‹Ÿé£ä¹¦åŒæ­¥çš„æ—¶é—´å¤„ç†é€»è¾‘
            publish_time = ''
            if tweet.publish_time:
                try:
                    if isinstance(tweet.publish_time, str):
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºdatetime
                        dt = parser.parse(tweet.publish_time)
                        # è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
                        publish_time = int(dt.timestamp() * 1000)
                        print(f"   - è§£æåçš„datetime: {dt}")
                    else:
                        # å¦‚æœå·²ç»æ˜¯datetimeå¯¹è±¡
                        publish_time = int(tweet.publish_time.timestamp() * 1000)
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨æŠ“å–æ—¶é—´ä½œä¸ºå¤‡é€‰
                    print(f"   - å‘å¸ƒæ—¶é—´è§£æå¤±è´¥: {e}, ä½¿ç”¨æŠ“å–æ—¶é—´ä½œä¸ºå¤‡é€‰")
                    publish_time = int(tweet.scraped_at.timestamp() * 1000)
            else:
                # å¦‚æœæ²¡æœ‰å‘å¸ƒæ—¶é—´ï¼Œä½¿ç”¨æŠ“å–æ—¶é—´
                publish_time = int(tweet.scraped_at.timestamp() * 1000)
            
            print(f"   - è½¬æ¢åçš„æ—¶é—´æˆ³: {publish_time}")
            
            # éªŒè¯æ—¶é—´æˆ³æ˜¯å¦åˆç†ï¼ˆè½¬æ¢å›æ—¥æœŸæŸ¥çœ‹ï¼‰
            if publish_time:
                converted_date = datetime.fromtimestamp(publish_time / 1000)
                print(f"   - éªŒè¯è½¬æ¢ç»“æœ: {converted_date}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯1970å¹´ï¼ˆé”™è¯¯çš„æ—¶é—´æˆ³ï¼‰
                if converted_date.year == 1970:
                    print(f"   - âš ï¸ è­¦å‘Š: æ—¶é—´æˆ³è½¬æ¢é”™è¯¯ï¼Œæ˜¾ç¤ºä¸º1970å¹´")
                else:
                    print(f"   - âœ… æ—¶é—´æˆ³è½¬æ¢æ­£ç¡®")

def test_feishu_data_format():
    """æµ‹è¯•é£ä¹¦æ•°æ®æ ¼å¼"""
    print("\nğŸ“‹ æµ‹è¯•é£ä¹¦æ•°æ®æ ¼å¼")
    print("=" * 50)
    
    with app.app_context():
        # è·å–ä¸€æ¡æ¨æ–‡æ•°æ®
        tweet = TweetData.query.first()
        
        if not tweet:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨æ–‡æ•°æ®")
            return
        
        # ä½¿ç”¨ä¿®å¤åçš„é€»è¾‘å‡†å¤‡æ•°æ®
        content_type = tweet.content_type or classify_content_type(tweet.content)
        
        # å¤„ç†å‘å¸ƒæ—¶é—´ - ä¿®å¤æ—¶é—´æˆ³è½¬æ¢é—®é¢˜
        publish_time = ''
        if tweet.publish_time:
            try:
                if isinstance(tweet.publish_time, str):
                    dt = parser.parse(tweet.publish_time)
                    publish_time = int(dt.timestamp() * 1000)
                else:
                    publish_time = int(tweet.publish_time.timestamp() * 1000)
            except Exception as e:
                print(f"å‘å¸ƒæ—¶é—´è§£æå¤±è´¥: {e}, ä½¿ç”¨æŠ“å–æ—¶é—´ä½œä¸ºå¤‡é€‰")
                publish_time = int(tweet.scraped_at.timestamp() * 1000)
        else:
            publish_time = int(tweet.scraped_at.timestamp() * 1000)
        
        # å‡†å¤‡é£ä¹¦æ•°æ®ï¼ˆç§»é™¤åˆ›å»ºæ—¶é—´å­—æ®µï¼‰
        feishu_data = {
            'æ¨æ–‡åŸæ–‡å†…å®¹': tweet.content,
            'å‘å¸ƒæ—¶é—´': publish_time,
            'ä½œè€…ï¼ˆè´¦å·ï¼‰': tweet.username,
            'æ¨æ–‡é“¾æ¥': tweet.link or '',
            'è¯é¢˜æ ‡ç­¾ï¼ˆHashtagï¼‰': ', '.join(json.loads(tweet.hashtags) if tweet.hashtags else []),
            'ç±»å‹æ ‡ç­¾': content_type,
            'è¯„è®º': 0,
            'ç‚¹èµ': tweet.likes,
            'è½¬å‘': tweet.retweets
            # æ³¨æ„ï¼šå·²ç§»é™¤åˆ›å»ºæ—¶é—´å­—æ®µï¼Œè®©é£ä¹¦è‡ªåŠ¨ç”Ÿæˆ
        }
        
        print("ğŸ“¤ å‡†å¤‡å‘é€åˆ°é£ä¹¦çš„æ•°æ®æ ¼å¼:")
        for key, value in feishu_data.items():
            if key == 'æ¨æ–‡åŸæ–‡å†…å®¹':
                print(f"   - {key}: {str(value)[:50]}...")
            elif key == 'å‘å¸ƒæ—¶é—´':
                # æ˜¾ç¤ºæ—¶é—´æˆ³å¯¹åº”çš„æ—¥æœŸ
                date_str = datetime.fromtimestamp(value / 1000).strftime('%Y-%m-%d %H:%M:%S')
                print(f"   - {key}: {value} ({date_str})")
            else:
                print(f"   - {key}: {value}")
        
        print("\nâœ… ä¿®å¤è¦ç‚¹:")
        print("   1. å‘å¸ƒæ—¶é—´ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´æˆ³è½¬æ¢")
        print("   2. ç§»é™¤äº†åˆ›å»ºæ—¶é—´å­—æ®µï¼Œè®©é£ä¹¦è‡ªåŠ¨ç”Ÿæˆ")
        print("   3. å¢åŠ äº†é”™è¯¯å¤„ç†ï¼Œè§£æå¤±è´¥æ—¶ä½¿ç”¨æŠ“å–æ—¶é—´ä½œä¸ºå¤‡é€‰")

if __name__ == '__main__':
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„é£ä¹¦åŒæ­¥æ—¶é—´é—®é¢˜")
    print("=" * 60)
    
    test_time_conversion()
    test_feishu_data_format()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ å¦‚æœæ—¶é—´æ˜¾ç¤ºæ­£ç¡®ï¼Œå¯ä»¥é‡æ–°åŒæ­¥æ•°æ®åˆ°é£ä¹¦è¿›è¡ŒéªŒè¯")