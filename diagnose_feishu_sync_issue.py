#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯Šæ–­é£ä¹¦åŒæ­¥é—®é¢˜
åˆ†æWebåº”ç”¨å’Œç‹¬ç«‹è„šæœ¬çš„å·®å¼‚
"""

import os
import sys
import json
import sqlite3
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def diagnose_database_connection():
    """è¯Šæ–­æ•°æ®åº“è¿æ¥é—®é¢˜"""
    print("\nğŸ” è¯Šæ–­1: æ•°æ®åº“è¿æ¥")
    print("=" * 40)
    
    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    db_paths = [
        '/Users/aron/twitter-daily-scraper/instance/twitter_scraper.db',
        '/Users/aron/twitter-daily-scraper/twitter_scraper.db',
        './instance/twitter_scraper.db',
        './twitter_scraper.db'
    ]
    
    for db_path in db_paths:
        if os.path.exists(db_path):
            print(f"âœ… æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {db_path}")
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # æ£€æŸ¥è¡¨ç»“æ„
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                tables = cursor.fetchall()
                print(f"   - è¡¨æ•°é‡: {len(tables)}")
                print(f"   - è¡¨å: {[t[0] for t in tables]}")
                
                # æ£€æŸ¥TweetDataè¡¨
                if ('tweet_data',) in tables:
                    cursor.execute("PRAGMA table_info(tweet_data);")
                    columns = cursor.fetchall()
                    print(f"   - TweetDataè¡¨å­—æ®µæ•°: {len(columns)}")
                    
                    # æ£€æŸ¥synced_to_feishuå­—æ®µ
                    synced_column = [c for c in columns if c[1] == 'synced_to_feishu']
                    if synced_column:
                        print(f"   - synced_to_feishuå­—æ®µç±»å‹: {synced_column[0][2]}")
                    
                    # æ£€æŸ¥æ•°æ®é‡
                    cursor.execute("SELECT COUNT(*) FROM tweet_data;")
                    total_count = cursor.fetchone()[0]
                    print(f"   - æ€»æ¨æ–‡æ•°: {total_count}")
                    
                    # æ£€æŸ¥åŒæ­¥çŠ¶æ€åˆ†å¸ƒ
                    cursor.execute("SELECT synced_to_feishu, COUNT(*) FROM tweet_data GROUP BY synced_to_feishu;")
                    sync_stats = cursor.fetchall()
                    print(f"   - åŒæ­¥çŠ¶æ€åˆ†å¸ƒ: {dict(sync_stats)}")
                    
                    # æ£€æŸ¥æœ€è¿‘çš„ä»»åŠ¡
                    cursor.execute("""
                        SELECT task_id, COUNT(*) as count, 
                               SUM(CASE WHEN synced_to_feishu = 1 THEN 1 ELSE 0 END) as synced_count
                        FROM tweet_data 
                        GROUP BY task_id 
                        ORDER BY task_id DESC 
                        LIMIT 5
                    """)
                    recent_tasks = cursor.fetchall()
                    print(f"   - æœ€è¿‘5ä¸ªä»»åŠ¡çš„åŒæ­¥æƒ…å†µ:")
                    for task_id, count, synced in recent_tasks:
                        print(f"     * ä»»åŠ¡{task_id}: {synced}/{count} å·²åŒæ­¥")
                
                conn.close()
                
            except Exception as e:
                print(f"   âŒ æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
        else:
            print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")

def diagnose_config_loading():
    """è¯Šæ–­é…ç½®åŠ è½½é—®é¢˜"""
    print("\nğŸ” è¯Šæ–­2: é…ç½®åŠ è½½")
    print("=" * 40)
    
    try:
        # æ¨¡æ‹ŸWebåº”ç”¨çš„é…ç½®åŠ è½½
        from web_app import FEISHU_CONFIG, ADS_POWER_CONFIG
        print("âœ… æˆåŠŸå¯¼å…¥Webåº”ç”¨é…ç½®")
        print(f"   - é£ä¹¦é…ç½®å¯ç”¨: {FEISHU_CONFIG.get('enabled')}")
        print(f"   - é£ä¹¦App ID: {FEISHU_CONFIG.get('app_id', '')[:8]}...")
        print(f"   - é£ä¹¦è¡¨æ ¼Token: {FEISHU_CONFIG.get('spreadsheet_token', '')[:8]}...")
        print(f"   - é£ä¹¦è¡¨æ ¼ID: {FEISHU_CONFIG.get('table_id')}")
        
    except Exception as e:
        print(f"âŒ Webåº”ç”¨é…ç½®åŠ è½½å¤±è´¥: {e}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_files = [
        './config/feishu_config.json',
        '/Users/aron/twitter-daily-scraper/config/feishu_config.json'
    ]
    
    for config_file in config_files:
        if os.path.exists(config_file):
            print(f"âœ… æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}")
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"   - é…ç½®å†…å®¹: {list(config.keys())}")
            except Exception as e:
                print(f"   âŒ é…ç½®æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
        else:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

def diagnose_time_handling():
    """è¯Šæ–­æ—¶é—´å¤„ç†é—®é¢˜"""
    print("\nğŸ” è¯Šæ–­3: æ—¶é—´å¤„ç†")
    print("=" * 40)
    
    # æµ‹è¯•ä¸åŒæ—¶é—´æ ¼å¼çš„å¤„ç†
    test_times = [
        datetime.now(),
        datetime.now().isoformat(),
        datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        int(datetime.now().timestamp()),
        int(datetime.now().timestamp() * 1000),
        '1970-01-01 00:00:01',
        0,
        1,
        None,
        ''
    ]
    
    print("æµ‹è¯•æ—¶é—´æ ¼å¼å¤„ç†:")
    for i, test_time in enumerate(test_times):
        print(f"\n   æµ‹è¯• {i+1}: {test_time} (ç±»å‹: {type(test_time)})")
        
        try:
            # æ¨¡æ‹ŸWebåº”ç”¨çš„æ—¶é—´å¤„ç†é€»è¾‘
            if test_time:
                if isinstance(test_time, str):
                    from dateutil import parser
                    dt = parser.parse(test_time)
                    timestamp = int(dt.timestamp() * 1000)
                    print(f"     - å­—ç¬¦ä¸²è§£æç»“æœ: {timestamp} ({datetime.fromtimestamp(timestamp/1000)})")
                elif hasattr(test_time, 'timestamp'):
                    timestamp = int(test_time.timestamp() * 1000)
                    print(f"     - datetimeå¯¹è±¡ç»“æœ: {timestamp} ({datetime.fromtimestamp(timestamp/1000)})")
                elif isinstance(test_time, (int, float)):
                    if test_time > 10000000000:  # æ¯«ç§’æ—¶é—´æˆ³
                        timestamp = test_time
                    else:  # ç§’æ—¶é—´æˆ³
                        timestamp = test_time * 1000
                    print(f"     - æ•°å­—å¤„ç†ç»“æœ: {timestamp} ({datetime.fromtimestamp(timestamp/1000)})")
                else:
                    timestamp = int(datetime.now().timestamp() * 1000)
                    print(f"     - é»˜è®¤å½“å‰æ—¶é—´: {timestamp} ({datetime.fromtimestamp(timestamp/1000)})")
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯1970å¹´é—®é¢˜
                if timestamp < 946684800000:  # 2000å¹´1æœˆ1æ—¥çš„æ¯«ç§’æ—¶é—´æˆ³
                    print(f"     - âš ï¸ æ£€æµ‹åˆ°1970å¹´é—®é¢˜!")
                    
            else:
                timestamp = int(datetime.now().timestamp() * 1000)
                print(f"     - ç©ºå€¼å¤„ç†ç»“æœ: {timestamp} ({datetime.fromtimestamp(timestamp/1000)})")
                
        except Exception as e:
            print(f"     - âŒ å¤„ç†å¼‚å¸¸: {e}")

def diagnose_web_vs_script_differences():
    """è¯Šæ–­Webåº”ç”¨å’Œç‹¬ç«‹è„šæœ¬çš„å·®å¼‚"""
    print("\nğŸ” è¯Šæ–­4: Webåº”ç”¨ vs ç‹¬ç«‹è„šæœ¬å·®å¼‚")
    print("=" * 40)
    
    print("ä¸»è¦å·®å¼‚åˆ†æ:")
    print("1. æ•°æ®åº“è¿æ¥æ–¹å¼:")
    print("   - Webåº”ç”¨: ä½¿ç”¨Flask-SQLAlchemy ORM")
    print("   - ç‹¬ç«‹è„šæœ¬: ç›´æ¥ä½¿ç”¨sqlite3è¿æ¥")
    
    print("\n2. é…ç½®åŠ è½½æ–¹å¼:")
    print("   - Webåº”ç”¨: ä»æ•°æ®åº“SystemConfigè¡¨åŠ è½½é…ç½®")
    print("   - ç‹¬ç«‹è„šæœ¬: ç›´æ¥ä½¿ç”¨ç¡¬ç¼–ç æˆ–æ–‡ä»¶é…ç½®")
    
    print("\n3. æ—¶é—´å¤„ç†å·®å¼‚:")
    print("   - Webåº”ç”¨: åœ¨è·¯ç”±ä¸­å¤„ç†æ—¶é—´ï¼Œè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³")
    print("   - ç‹¬ç«‹è„šæœ¬: åœ¨cloud_sync.pyä¸­å¤„ç†æ—¶é—´ï¼Œè½¬æ¢ä¸ºç§’æ—¶é—´æˆ³")
    
    print("\n4. æ•°æ®æŸ¥è¯¢å·®å¼‚:")
    print("   - Webåº”ç”¨: ä½¿ç”¨SQLAlchemyæŸ¥è¯¢ synced_to_feishu=0")
    print("   - ç‹¬ç«‹è„šæœ¬: å¯èƒ½ä½¿ç”¨ä¸åŒçš„æŸ¥è¯¢æ¡ä»¶")
    
    print("\n5. äº‹åŠ¡å¤„ç†å·®å¼‚:")
    print("   - Webåº”ç”¨: ä½¿ç”¨Flask-SQLAlchemyçš„äº‹åŠ¡ç®¡ç†")
    print("   - ç‹¬ç«‹è„šæœ¬: æ‰‹åŠ¨ç®¡ç†æ•°æ®åº“äº‹åŠ¡")

def suggest_solutions():
    """æä¾›è§£å†³æ–¹æ¡ˆå»ºè®®"""
    print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®")
    print("=" * 40)
    
    solutions = [
        {
            "é—®é¢˜": "æ—¶é—´æˆ³æ ¼å¼ä¸ä¸€è‡´",
            "è§£å†³æ–¹æ¡ˆ": [
                "ç»Ÿä¸€ä½¿ç”¨ç§’çº§æ—¶é—´æˆ³ï¼ˆè€Œéæ¯«ç§’ï¼‰",
                "åœ¨Webåº”ç”¨ä¸­ä¿®æ”¹æ—¶é—´å¤„ç†é€»è¾‘ï¼Œä¸cloud_sync.pyä¿æŒä¸€è‡´",
                "æ·»åŠ æ—¶é—´æˆ³éªŒè¯ï¼Œç¡®ä¿ä¸ä¼šå‡ºç°1970å¹´é—®é¢˜"
            ]
        },
        {
            "é—®é¢˜": "æ•°æ®åº“æŸ¥è¯¢æ¡ä»¶ä¸ä¸€è‡´",
            "è§£å†³æ–¹æ¡ˆ": [
                "ç¡®ä¿Webåº”ç”¨å’Œç‹¬ç«‹è„šæœ¬ä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢æ¡ä»¶",
                "ç»Ÿä¸€ä½¿ç”¨æ•´æ•°0/1è€Œéå¸ƒå°”å€¼True/False",
                "æ·»åŠ è°ƒè¯•æ—¥å¿—ç¡®è®¤æŸ¥è¯¢ç»“æœ"
            ]
        },
        {
            "é—®é¢˜": "é…ç½®åŠ è½½å·®å¼‚",
            "è§£å†³æ–¹æ¡ˆ": [
                "ç¡®ä¿Webåº”ç”¨æ­£ç¡®åŠ è½½æ•°æ®åº“ä¸­çš„é£ä¹¦é…ç½®",
                "æ·»åŠ é…ç½®éªŒè¯é€»è¾‘",
                "ç»Ÿä¸€é…ç½®åŠ è½½æ–¹å¼"
            ]
        },
        {
            "é—®é¢˜": "äº‹åŠ¡å¤„ç†å·®å¼‚",
            "è§£å†³æ–¹æ¡ˆ": [
                "ç¡®ä¿Webåº”ç”¨æ­£ç¡®æäº¤æ•°æ®åº“äº‹åŠ¡",
                "æ·»åŠ å¼‚å¸¸å¤„ç†å’Œå›æ»šé€»è¾‘",
                "ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“è¿æ¥æ–¹å¼"
            ]
        }
    ]
    
    for i, solution in enumerate(solutions, 1):
        print(f"\n{i}. {solution['é—®é¢˜']}:")
        for j, step in enumerate(solution['è§£å†³æ–¹æ¡ˆ'], 1):
            print(f"   {j}) {step}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ é£ä¹¦åŒæ­¥é—®é¢˜è¯Šæ–­å·¥å…·")
    print("=" * 50)
    print(f"è¯Šæ–­æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ‰§è¡Œå„é¡¹è¯Šæ–­
    diagnose_database_connection()
    diagnose_config_loading()
    diagnose_time_handling()
    diagnose_web_vs_script_differences()
    suggest_solutions()
    
    print("\n" + "=" * 50)
    print("ğŸ è¯Šæ–­å®Œæˆ")
    print("ğŸ’¡ è¯·æ ¹æ®è¯Šæ–­ç»“æœå’Œå»ºè®®è¿›è¡Œç›¸åº”çš„ä¿®å¤")

if __name__ == "__main__":
    main()