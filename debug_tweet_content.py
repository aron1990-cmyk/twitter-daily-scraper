#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•æ¨æ–‡å†…å®¹æå–é—®é¢˜
åˆ†æä¸ºä»€ä¹ˆæŸäº›æ¨æ–‡æ— æ³•æå–æ–‡æœ¬å†…å®¹
"""

import asyncio
import logging
import sys
import os
from playwright.async_api import async_playwright

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from ads_browser_launcher import AdsPowerLauncher

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# AdsPoweré…ç½®
ADS_POWER_CONFIG = {
    'user_id': 'k11p9ypc',
    'open_tabs': 1,
    'launch_args': [],
    'headless': False,
    'disable_password_filling': False,
    'clear_cache_after_closing': False,
    'enable_password_saving': False
}

async def debug_tweet_content_extraction():
    """è°ƒè¯•æ¨æ–‡å†…å®¹æå–"""
    launcher = None
    
    try:
        # å¯åŠ¨æµè§ˆå™¨
        logger.info("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        launcher = AdsPowerLauncher(ADS_POWER_CONFIG)
        browser_info = launcher.start_browser()
        launcher.wait_for_browser_ready()
        debug_port = launcher.get_debug_port()
        logger.info(f"âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼Œè°ƒè¯•ç«¯å£: {debug_port}")
        
        async with async_playwright() as p:
            logger.info(f"è¿æ¥åˆ°æµè§ˆå™¨: {debug_port}")
            browser = await p.chromium.connect_over_cdp(debug_port)
            
            # è·å–ç°æœ‰ä¸Šä¸‹æ–‡å’Œé¡µé¢
            contexts = browser.contexts
            if not contexts:
                logger.error("æ²¡æœ‰æ‰¾åˆ°æµè§ˆå™¨ä¸Šä¸‹æ–‡")
                return
            
            context = contexts[0]
            pages = context.pages
            if not pages:
                logger.error("æ²¡æœ‰æ‰¾åˆ°é¡µé¢")
                return
            
            page = pages[0]
            current_url = page.url
            logger.info(f"ğŸ“ å½“å‰é¡µé¢: {current_url}")
            
            # å¦‚æœä¸åœ¨Twitteré¡µé¢ï¼Œå¯¼èˆªåˆ°Elon Muské¡µé¢
            if 'elonmusk' not in current_url:
                logger.info("ğŸ”„ å¯¼èˆªåˆ°@elonmuské¡µé¢...")
                await page.goto('https://x.com/elonmusk', wait_until='domcontentloaded')
                await asyncio.sleep(10)
                logger.info("âœ… å·²å¯¼èˆªåˆ°@elonmuské¡µé¢")
            
            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            logger.info("â³ ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½...")
            await asyncio.sleep(5)
            
            # è·å–æ‰€æœ‰æ¨æ–‡å…ƒç´ 
            tweet_elements = await page.query_selector_all('[data-testid="tweet"]')
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(tweet_elements)} ä¸ªæ¨æ–‡å…ƒç´ ")
            
            if len(tweet_elements) == 0:
                logger.warning("âŒ æœªæ‰¾åˆ°æ¨æ–‡å…ƒç´ ")
                return
            
            # åˆ†ææ¯ä¸ªæ¨æ–‡å…ƒç´ 
            for i, tweet_element in enumerate(tweet_elements[:5]):  # åªåˆ†æå‰5ä¸ª
                logger.info(f"\nğŸ” åˆ†ææ¨æ–‡ {i+1}:")
                
                try:
                    # æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§
                    is_visible = await tweet_element.is_visible()
                    logger.info(f"  å…ƒç´ å¯è§æ€§: {is_visible}")
                    
                    # è·å–å…ƒç´ çš„HTMLç»“æ„
                    element_html = await tweet_element.inner_html()
                    logger.info(f"  HTMLé•¿åº¦: {len(element_html)} å­—ç¬¦")
                    
                    # æµ‹è¯•å„ç§å†…å®¹é€‰æ‹©å™¨
                    content_selectors = [
                        '[data-testid="tweetText"]',
                        '[data-testid="tweetText"] span',
                        'div[lang] span',
                        'div[dir="auto"] span',
                        'div[dir="ltr"] span',
                        'div[dir="rtl"] span',
                        '[lang] span',
                        'span[dir="auto"]',
                        'div[data-testid="tweetText"] > span',
                        'article div[lang] span',
                        'article span[dir]',
                        # æ–°å¢æ›´å¤šé€‰æ‹©å™¨
                        'div[data-testid="tweetText"] div',
                        'div[data-testid="tweetText"] *',
                        '[data-testid="tweetText"] div[dir]',
                        '[data-testid="tweetText"] span[dir]',
                        'span[lang]',
                        'div[lang]'
                    ]
                    
                    found_content = False
                    
                    for j, selector in enumerate(content_selectors):
                        try:
                            content_elements = await tweet_element.query_selector_all(selector)
                            if content_elements:
                                # æ”¶é›†æ‰€æœ‰æ–‡æœ¬å†…å®¹
                                text_parts = []
                                for elem in content_elements:
                                    text = await elem.inner_text()
                                    if text and text.strip():
                                        text_parts.append(text.strip())
                                
                                if text_parts:
                                    content_text = ' '.join(text_parts)
                                    logger.info(f"  âœ… é€‰æ‹©å™¨ {j+1} '{selector}': æ‰¾åˆ°å†…å®¹")
                                    logger.info(f"     å†…å®¹: {content_text[:100]}...")
                                    found_content = True
                                    break
                                else:
                                    logger.debug(f"  âšª é€‰æ‹©å™¨ {j+1} '{selector}': æ‰¾åˆ°å…ƒç´ ä½†æ— æ–‡æœ¬")
                            else:
                                logger.debug(f"  âŒ é€‰æ‹©å™¨ {j+1} '{selector}': æœªæ‰¾åˆ°å…ƒç´ ")
                        except Exception as e:
                            logger.debug(f"  âš ï¸ é€‰æ‹©å™¨ {j+1} '{selector}': æµ‹è¯•å¤±è´¥ - {e}")
                    
                    # å¦‚æœæ‰€æœ‰é€‰æ‹©å™¨éƒ½å¤±è´¥ï¼Œå°è¯•è·å–æ•´ä¸ªæ¨æ–‡çš„æ–‡æœ¬
                    if not found_content:
                        logger.info(f"  ğŸ”„ æ‰€æœ‰å†…å®¹é€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•è·å–æ•´ä¸ªæ¨æ–‡æ–‡æœ¬...")
                        try:
                            all_text = await tweet_element.inner_text()
                            if all_text:
                                logger.info(f"  ğŸ“ æ•´ä¸ªæ¨æ–‡æ–‡æœ¬: {all_text[:200]}...")
                                
                                # åˆ†ææ–‡æœ¬ç»“æ„
                                lines = all_text.split('\n')
                                logger.info(f"  ğŸ“‹ æ–‡æœ¬è¡Œæ•°: {len(lines)}")
                                
                                for line_idx, line in enumerate(lines[:10]):  # åªæ˜¾ç¤ºå‰10è¡Œ
                                    line = line.strip()
                                    if line:
                                        logger.info(f"    è¡Œ {line_idx+1}: {line[:50]}...")
                                
                                # å°è¯•æ™ºèƒ½è¿‡æ»¤å†…å®¹
                                filtered_lines = []
                                for line in lines:
                                    line = line.strip()
                                    # è·³è¿‡ç©ºè¡Œã€ç”¨æˆ·åã€æ—¶é—´æˆ³ç­‰
                                    if (line and 
                                        not line.startswith('@') and 
                                        not line.endswith('h') and 
                                        not line.endswith('m') and 
                                        not line.endswith('s') and
                                        not line.isdigit() and
                                        len(line) > 3 and
                                        not line in ['Like', 'Reply', 'Retweet', 'Share', 'View']):
                                        filtered_lines.append(line)
                                
                                if filtered_lines:
                                    filtered_content = ' '.join(filtered_lines[:3])
                                    logger.info(f"  âœ… è¿‡æ»¤åå†…å®¹: {filtered_content[:100]}...")
                                else:
                                    logger.warning(f"  âš ï¸ è¿‡æ»¤åæ— æœ‰æ•ˆå†…å®¹")
                            else:
                                logger.warning(f"  âŒ æ•´ä¸ªæ¨æ–‡å…ƒç´ æ— æ–‡æœ¬å†…å®¹")
                        except Exception as e:
                            logger.warning(f"  âŒ è·å–æ•´ä¸ªæ¨æ–‡æ–‡æœ¬å¤±è´¥: {e}")
                    
                    # æ£€æŸ¥æ¨æ–‡çš„ç‰¹æ®Šç±»å‹
                    logger.info(f"  ğŸ” æ£€æŸ¥æ¨æ–‡ç‰¹æ®Šç±»å‹...")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è½¬å‘
                    retweet_indicators = [
                        '[data-testid="socialContext"]',
                        'span[data-testid="socialContext"]',
                        '[aria-label*="retweeted"]',
                        '[aria-label*="Retweeted"]'
                    ]
                    
                    for indicator in retweet_indicators:
                        try:
                            retweet_element = await tweet_element.query_selector(indicator)
                            if retweet_element:
                                retweet_text = await retweet_element.inner_text()
                                logger.info(f"    ğŸ”„ è½¬å‘æŒ‡ç¤ºå™¨: {retweet_text}")
                                break
                        except Exception:
                            continue
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¼•ç”¨æ¨æ–‡
                    quote_indicators = [
                        '[data-testid="quoteTweet"]',
                        'div[role="blockquote"]',
                        '[data-testid="card.wrapper"]'
                    ]
                    
                    for indicator in quote_indicators:
                        try:
                            quote_element = await tweet_element.query_selector(indicator)
                            if quote_element:
                                logger.info(f"    ğŸ“ å‘ç°å¼•ç”¨æ¨æ–‡å…ƒç´ ")
                                break
                        except Exception:
                            continue
                    
                    # æ£€æŸ¥æ˜¯å¦åªæœ‰åª’ä½“å†…å®¹
                    media_indicators = [
                        '[data-testid="tweetPhoto"]',
                        '[data-testid="videoPlayer"]',
                        'img[alt*="Image"]',
                        'video'
                    ]
                    
                    media_found = False
                    for indicator in media_indicators:
                        try:
                            media_element = await tweet_element.query_selector(indicator)
                            if media_element:
                                logger.info(f"    ğŸ–¼ï¸ å‘ç°åª’ä½“å†…å®¹: {indicator}")
                                media_found = True
                        except Exception:
                            continue
                    
                    if media_found and not found_content:
                        logger.info(f"    ğŸ’¡ å¯èƒ½æ˜¯çº¯åª’ä½“æ¨æ–‡ï¼ˆæ— æ–‡å­—å†…å®¹ï¼‰")
                    
                except Exception as e:
                    logger.error(f"  âŒ åˆ†ææ¨æ–‡ {i+1} å¤±è´¥: {e}")
            
            logger.info("\nâœ… æ¨æ–‡å†…å®¹æå–è°ƒè¯•å®Œæˆ")
            
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        
    finally:
        # æ¸…ç†èµ„æº
        if launcher:
            try:
                launcher.stop_browser()
                logger.info("âœ… æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(debug_tweet_content_extraction())